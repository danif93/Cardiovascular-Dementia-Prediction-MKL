{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import Utils as ut\n",
    "import CortesAlignmentFile as ca\n",
    "import mySampler as ms\n",
    " \n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "\n",
    "from threading import Thread, Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_clinical = pd.read_csv(os.path.join('data', 'dataset_clinical_cleaned.csv'))\n",
    "d_genetic = pd.read_csv(os.path.join('data', 'dataset_genetic_cleaned_noOHE.csv'))\n",
    "d_vampire = pd.read_csv(os.path.join('data', 'dataset_vampire_cleaned.csv'))\n",
    "outputs = pd.read_csv(os.path.join('data', 'outputs_cleaned.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = d_clinical.values\n",
    "G = d_genetic.values\n",
    "V = d_vampire.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d = outputs[\"dement_fail\"].values\n",
    "y_c = outputs[\"cvd_fail\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTATIONAL COMPLEXITY: Reduce #samples\n",
    "tr_idx, ts_idx = next(StratifiedShuffleSplit(n_splits=1, test_size=0.25).split(C, y_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_ = C[tr_idx]\n",
    "C_test = C[ts_idx]\n",
    "G_ = G[tr_idx]\n",
    "G_test = G[ts_idx]\n",
    "V_ = V[tr_idx]\n",
    "V_test = V[ts_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_d_ = y_d[tr_idx]\n",
    "y_d_test = y_d[ts_idx]\n",
    "\n",
    "y_c_ = y_c[tr_idx]\n",
    "y_c_test = y_c[ts_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = [C_, G_, V_]\n",
    "ds_test = [C_test, G_test, V_test]\n",
    "ds_names = ['clinic', 'genetic', 'vampire']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_0 = ['laplacian', 'gaussian']\n",
    "kernel_type_0 = [{'laplacian':[0.2, 0.6], 'gaussian':[0.3, 0.7]},\n",
    "               {'laplacian':[0.4, 0.9], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_1 = ['linear', 'gaussian']\n",
    "kernel_type_1 = [{'linear':[1], 'gaussian':[0.4, 0.7]},\n",
    "               {'linear':[1], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_2 = ['polynomial', 'gaussian']\n",
    "kernel_type_2 = [{'polynomial':[2, 7], 'gaussian':[0.4, 0.7]},\n",
    "               {'polynomial':[3, 5], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_3 = ['sigmoid', 'gaussian']\n",
    "kernel_type_3 = [{'sigmoid':[0.2, 0.6], 'gaussian':[0.3, 0.7]},\n",
    "               {'sigmoid':[0.4, 0.9], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_dementia = Lock()\n",
    "lock_cardio = Lock()\n",
    "\n",
    "kernel_names = [kernel_names_0, kernel_names_1, kernel_names_2, kernel_names_3]\n",
    "kernel_types = [kernel_type_0, kernel_type_1, kernel_type_2, kernel_type_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other shared parameters initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ca.centeredKernelAlignment\n",
    "\n",
    "threads = []\n",
    "\n",
    "valid_fold = 3\n",
    "\n",
    "exclusion_list = [[5,6,7,9,10,13,15,16,17,18,19], list(range(G.shape[1]-3)), []]\n",
    "\n",
    "l1_params = [0.1, 0.3, 0.5, 0.7, 0.1]\n",
    "l2_params = [0.1, 0.3, 0.5, 0.7, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeKernels(sampler, estimator, penalty_type, parameter, ds_list, ds_test, y_d_, y_d_test, y_c_, y_c_test, valid_fold, exclusion_list, verbose, approach):\n",
    "    \n",
    "    results = np.empty(len(kernel_names)*2)\n",
    "    \n",
    "    for idx, (k_names, k_type) in enumerate(zip(kernel_names, kernel_types)):\n",
    "          \n",
    "        #DEMENTIA\n",
    "        result = sampler.sample(k_type, estimator, ds_list, y_d_, valid_fold=valid_fold, verbose=verbose, exclusion_list=exclusion_list)\n",
    "        w_dict, w_list = result.votingOverCA(ds_names, k_names)\n",
    "        ut.testConfigurations(estimator, penalty_type, parameter, y_d_, y_d_test, w_list, ds_list, ds_test, k_names, 'classification', verbose=verbose)\n",
    "        outcome_dict = result.performancesFeatures(verbose=verbose)\n",
    "        results[idx] = outcome_dict['CA'][0]\n",
    "        \n",
    "        # CARDIO\n",
    "        result = sampler.sample(k_type, estimator, ds_list, y_c_, valid_fold=valid_fold, verbose=verbose, exclusion_list=exclusion_list)\n",
    "        w_dict, w_list = result.votingOverCA(ds_names, k_names)\n",
    "        ut.testConfigurations(estimator, penalty_type, parameter, y_c_, y_c_test, w_list, ds_list, ds_test, k_names, 'classification', verbose=verbose)\n",
    "        outcome_dict = result.performancesFeatures(verbose=verbose)\n",
    "        results[idx+4] = outcome_dict['CA'][0]\n",
    "    \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectParam(params, penalty_type, train_set_list, train_label_c, train_label_d, estimator, approach, n_splits=3, centering=False, normalizing=False, normalize_kernels=False, exclusion_list=None, verbose=False):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=False)\n",
    "    n_params = len(params)\n",
    "    n_kernels = len(kernel_names)*2 # *2 datasets\n",
    "    \n",
    "    results = np.zeros((n_params, n_kernels))\n",
    "    \n",
    "    for tr_idx, val_idx in skf.split(train_set_list[0], train_label):\n",
    "        tr_set_list = [X[tr_idx] for X in train_set_list]\n",
    "        val_set_list = [X[val_idx] for X in train_set_list]\n",
    "        tr_label_c = train_label_c[tr_idx]\n",
    "        tr_label_d = train_label_d[tr_idx]\n",
    "        val_label_c = train_label_c[val_idx]\n",
    "        val_label_d = train_label_d[val_idx]\n",
    "        \n",
    "        for idx, param in enumerate(params):\n",
    "            if penalty_type == 'l1':\n",
    "                sampler = ms.mySampler(n_splits=3, test_size=.25, sparsity=param, centering=centering, normalizing=normalizing, normalize_kernels=normalize_kernels)\n",
    "            elif penalty_type == 'l2':\n",
    "                sampler = ms.mySampler(n_splits=3, test_size=.25, lamb=param, centering=centering, normalizing=normalizing, normalize_kernels=normalize_kernels)\n",
    "            else:\n",
    "                raise ValueError('Penalty type not set properly')\n",
    "            \n",
    "            results[idx] += executeKernels(sampler, estimator, penalty_type, param, tr_set_list, val_set_list, tr_label_d, val_label_d, tr_label_c, val_label_c, n_splits, exclusion_list, verbose, approach)\n",
    "    results /= skf.get_n_splits\n",
    "    avg_results = np.sum(results, axis=0)/n_kernels\n",
    "    print(approach+\"\\n\"+avg_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Penalty, Origin Data  Centering and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = ms.mySampler(n_splits=3, test_size=.25, lamb = 0.5, centering = True, normalizing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l2_params, 'l2', ds_list, y_c_, y_d_, estimator, 'Centering - Normalizing', valid_fold, True, True, False, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Penalty, Origin Data  Centering and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = ms.mySampler(n_splits=3, test_size=.25, sparsity = 0.7, centering = True, normalizing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l1_params, 'l1', ds_list, y_c_, y_d_, estimator, 'Centering - Normalizing', valid_fold, True, True, False, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Penalty, Normalization, Kernel Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = ms.mySampler(n_splits=3, test_size=.25, lamb = 0.5, normalizing = True, normalize_kernels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l2_params, 'l2', ds_list, y_c_, y_d_, estimator, 'Normalizing - K Normalizing', valid_fold, False, True, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Penalty, Normalization, Kernel Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = ms.mySampler(n_splits=3, test_size=.25, sparsity = 0.7, normalizing = True, normalize_kernels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l1_params, 'l1', ds_list, y_c_, y_d_, estimator, 'Normalizing - K Normalizing', valid_fold, False, True, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Penalty, Centering, Normalization, Kernel Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = ms.mySampler(n_splits=3, test_size=.25, lamb = 0.5, centering = True, normalizing = True, normalize_kernels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l2_params, 'l2', ds_list, y_c_, y_d_, estimator, 'Centering - Normalizing - K Normalizing', valid_fold, True, True, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Penalty, Centering, Normalization, Kernel Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = ms.mySampler(n_splits=3, test_size=.25, sparsity = 0.7, centering = True, normalizing = True, normalize_kernels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l1_params, 'l1', ds_list, y_c_, y_d_, estimator, 'Centering - Normalizing - K Normalizing', valid_fold, True, True, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Penalty, Centering, K-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = ms.mySampler(n_splits=3, test_size=0.25, lamb = 0.5, centering = True, normalize_kernels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l2_params, 'l2', ds_list, y_c_, y_d_, estimator, 'Centering - K Normalizing', valid_fold, True, False, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Penalty, Centering, K-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampler = ms.mySampler(n_splits=3, test_size=.25, sparsity = 0.7, centering = True, normalize_kernels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l1_params, 'l1', ds_list, y_c_, y_d_, estimator, 'Centering - K Normalizing', valid_fold, True, False, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Operations completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
