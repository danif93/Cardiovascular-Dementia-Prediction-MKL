{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:\"AMS\"}}});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:\"AMS\"}}});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCB Final Project - a.y. 17/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>Fiaschi Lorenzo, Franco Danilo</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol> <b>TODO</b>\n",
    "    <li><strike>problem presentation (dataset, objectives)</strike></li>\n",
    "    <li><strike>preprocessing</strike></li>\n",
    "    <li><strike>mkl procedure overview</strike></li>\n",
    "    <li><strike>chosen model description (alignment model, cortes approach)</strike></li>\n",
    "    <li><strike>algorithm pipeline (with a major point in the cross-validation decisions, how it is shuffled...)</strike></li>\n",
    "    <li><strike>approach settings</strike></li>\n",
    "    <li>performances over toy (with description on how it is generated</li>\n",
    "    <li>integration needed? comparison with single dataset model</li>\n",
    "    <li>performances over real dataset</li>\n",
    "    <li>integration needed? comparison with single dataset model</li>\n",
    "    <li>what we can learn from the best configuration (sparsity)</li>\n",
    "    <li>kernel integration on the only meaningful dataset (clinical)</li>\n",
    "    <li>overview on the regression approach</li>\n",
    "    <li>regression performances with data integration</li>\n",
    "    <li>single kernel approach after regression results</li>\n",
    "    <li>final comments over the results</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Problem\n",
    "The dataset consists of 2741 aligned patients affected by Diabetes; it is structured in 3 differents tables:\n",
    "<ol>\n",
    "    <li><b>Genetic Features</b>, 347 - Related to the SNP of 344 genes + 3 composite genes scores [blood pressure, alzheimer, CVD]</li>\n",
    "    <li><b>Retina's Features</b>, 157 - Engineered features extracted from patients' retinas</li>\n",
    "    <li><b>Clinical Features</b>, 15 - General patients' information</li>\n",
    "</ol>\n",
    "The objective of the study is to find a model that is able to predict whether a patient will incurr in either cardiovascular failures or in episodes of dementia.\n",
    "In the positive case, it is also aked to predict at which age this episodes will occurr.\n",
    "In order to learn such model, the output dataset has been provided; it is composed by two information, both for the occurrence of a cardiovascular failure and for the dementia episode: whether the episode has happened or not and at what age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing\n",
    "In order to be fed, the tables have been cleaned as follows:\n",
    "<ul>\n",
    "    <li>\n",
    "        <b><i>NaN Filling</i></b>: \n",
    "        <ul>\n",
    "            <li>\n",
    "                Clinical DS: \n",
    "                <ul>\n",
    "                    <li>\n",
    "                        [\"therapy\",\"gender\",\"precedent CVD\", \"smoker\"] $\\rightarrow$ most frequent;\n",
    "                    </li>\n",
    "                    <li>\n",
    "                        Others $\\rightarrow$ mean.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            <li>\n",
    "                Genetic DS: \n",
    "                <ul>\n",
    "                    <li>\n",
    "                        [composite gene scores] $\\rightarrow$ mean;\n",
    "                    </li>\n",
    "                    <li>\n",
    "                        Others $\\rightarrow$ min.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            <li>\n",
    "                Vampire DS: \n",
    "                <ul>\n",
    "                    <li>\n",
    "                        All $\\rightarrow$ mean.\n",
    "                    </li>\n",
    "                </ul>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b><i>One-Hot Encoding</i></b>:\n",
    "        <ul>\n",
    "            <li>Clinical DS:\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        \"therapy\" and \"Apoe4Presence\".\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b><i>Boolean: from binary to symmetric</i></b>: \n",
    "        <ul>\n",
    "            <li>Clinical DS:\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        [\"gender\",\"precedent CVD\", \"smoker\"] $\\rightarrow$ from [0,1] to [-1,1].\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>Outputs:\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        [\"cvd_fail\",\"dement_fail\"] $\\rightarrow$ from [0,1] to [-1,1].\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multiple Kernel Learning\n",
    "<b>Multiple Kernel Learning</b> refers to a set of machine learning methods that use a predefined set of kernels and learn an optimal linear or non-linear combination of kernels as part of the algorithm.<br>\n",
    "Reasons to use multiple kernel learning include:\n",
    "<ul>\n",
    "    <li>the ability to select for an optimal kernel and parameters from a larger set of kernels, reducing bias due to kernel selection while allowing for more automated machine learning methods;\n",
    "    </li>\n",
    "    <li>combining data from different sources (e.g. sound and images from a video) that have different notions of similarity and thus require different kernels;\n",
    "    </li>\n",
    "</ul>\n",
    "<img src='others/mkl.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The Model\n",
    "<ul>\n",
    "    <li><b><i>Target Function</i></b> $\\rightarrow$ Similarity-based function; it uses a similarity metric between the combined kernel matrix and an optimum kernel matrix calculated from the training data, in order to select the combination function parameters that maximize the similarity. The similarity between two kernel matrices can be calculated using kernel alignment, Euclidean distance, Kullback-Leibler (KL) divergence, or any other similarity measure.\n",
    "    </li>\n",
    "    <li><b><i>Training Method</i></b> $\\rightarrow$ One-step method; it calculates both the combination function parameters and the parameters of the combined base learner in a single pass. One can use a sequential approach or a simultaneous approach. In the sequential approach, the combination function parameters are determined first, and then a kernel-based learner is trained using the combined kernel. In the simultaneous approach, both set of parameters are learned together.\n",
    "    </li>\n",
    "</ul>\n",
    "The chosen algorithm is called <i>Centered-kernel alignment</i> [1] and its main purpose is to compute a set of $P$ kernels $K_i$, $i \\, = \\, 1...P$ from the datasets and to use a linear combination of them to approximate an ideal kernel. Then the obtained approximated kernel can be used for both classification and regression purposes. The functional is:<br>\n",
    "\n",
    "\\begin{equation}\n",
    "\\max\\limits_{\\eta \\in \\mathcal{M}} CA(K_{\\eta}, IK)\n",
    "\\label{eq:problem}\n",
    "\\end{equation}\n",
    "\n",
    "where $IK = y^T y$ is the ideal kernel, $K_{\\eta} = \\sum\\limits_{i=1}^P K_i \\eta_i$ is its approximation and $\\mathcal{M}=\\{\\eta : ||\\eta||_2 = 1\\}$ imposing $\\eta$ being a unit norm vector. In turn, $CA(K_1, K_2)$ is defined as\n",
    "\n",
    "\\begin{equation*}\n",
    "CA(K_1^c, K_2^c) = \\frac{\\langle K_1^c, K_2^c \\rangle_F}{\\sqrt{\\langle K_1^c, K_1^c\\rangle_F \\; \\langle K_2^c, K_2^c \\rangle_F}}\n",
    "\\end{equation*}\n",
    "\n",
    "with $K^c$ is the centered version of $K$ and can be calculated as\n",
    "\n",
    "\\begin{equation*}\n",
    "K^c = K - \\frac{1}{N} 11^TK - \\frac{1}{N} K11^T + \\frac{1}{N^2} \\left(1^TK1\\right)11^T\n",
    "\\end{equation*}\n",
    "\n",
    "where $1$ is the vector of ones with proper dimension.\n",
    "\n",
    "The optimization problem \\eqref{eq:problem} has then a unique analytical solution\n",
    "\n",
    "\\begin{equation}\n",
    "\\eta = \\frac{M^{-1}a}{||M^{-1}a||_2}\n",
    "\\label{eq:problem_solution}\n",
    "\\end{equation}\n",
    "\n",
    "where $M = \\{\\langle K_m, K_h\\rangle_F\\}_{m,h \\, = \\, 1}^P$ and $a = \\{\\langle K_m, IK\\rangle_F\\}_{m \\, = \\, 1}^P$.\n",
    "\n",
    "In order to avoid overfitting, to be more robust in the learning procedure and in order to get deeper insights of the problem we added either an $L_1$ or $L_2$ penalty to the functional \\eqref{eq:problem}, obtaining the following two reformulations\n",
    "\n",
    "\\begin{equation}\n",
    "\\max\\limits_{\\eta \\in \\mathcal{M}} CA(K_{\\eta}, IK) - \\lambda ||\\eta||_2^2 \\;\\; (a), \\qquad \\max\\limits_{\\eta \\in \\mathcal{M}} CA(K_{\\eta}, IK) - c ||\\eta||_1 \\;\\; (b).\n",
    "\\label{eq:problem_penalty}\n",
    "\\end{equation}\n",
    "\n",
    "While the Equation \\eqref{eq:problem_penalty}(a) has the unique analytical solution \n",
    "\n",
    "\\begin{equation}\n",
    "\\eta = \\frac{(M-\\lambda I)^{-1}a}{||(M-\\lambda I)^{-1}a||_2}\n",
    "\\label{eq:problem_solution_lambda}\n",
    "\\end{equation}\n",
    "\n",
    "Equation \\eqref{eq:problem_penalty}(b) does not due to the non-differentiability of the $L_1$ norm. To converge to one of the optima we applied the forward-backward splitting method [2][3]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. The Algorithm\n",
    "\n",
    "<ol>\n",
    "    <li><i>Datasets loading</i> $\\rightarrow$ (Clinical, Genetic, Vampire, Outputs);</li>\n",
    "    <li><i>Outer split</i> $\\rightarrow$ 75% training + 25% test for final testing purposes;</li>\n",
    "    <li><i>Kernel definition</i> $\\rightarrow$ dictionary list: [{<b>kernelType1:[parameter list]</b>, <b>kernelType2:[parameter list]</b>, <b>...</b> }, <b>...</b> ] </li>\n",
    "    <li><i>Sampling rounds</i> $\\rightarrow$ 3 rounds of 75% training + 25% mid test (extracted from the previous 75% of training) for statistical stability:\n",
    "        <ol>\n",
    "            <li>If stated, perform training matrix centering and/or normalisation;</li>\n",
    "            <li>For each dictionary configuration:\n",
    "                <ol>\n",
    "                    <li><i>If regression</i>: Normalize the sampling training outputs (store aside one non normalised version);</li>\n",
    "                    <li>Build the ideal kernel from the training outputs;</li>\n",
    "                    <li>Build all the possible combination between the kernels parameters;</li>\n",
    "                    <li>3-Fold cross validation over the 75% sampling training:\n",
    "                        <ol>\n",
    "                            <li><i>If regression</i>: Normalize the sampling training and validation outputs with their respective 2-norms;</li>\n",
    "                            <li>Build the ideal kernel matrices from both training and validation output sets;</li>\n",
    "                            <li>For each configurations:\n",
    "                                <ol>\n",
    "                                    <li>Compute all the kernel matrices for that configuration;</li>\n",
    "                                    <li>Find the optimal weights for those kernel matrices using the ideal training kernel;</li>\n",
    "                                    <li>Compute the weighted sum of the kernel matrices;</li>\n",
    "                                    <li>Compare the obtained matrix with the ideal validation kernel using the Cortes Alignment metric and store this similarity measure;</li>\n",
    "                                </ol>\n",
    "                            </li>\n",
    "                        </ol>                       \n",
    "                    </li>\n",
    "                    <li>Find the configuration with greatest mean across the three validation fold;</li>\n",
    "                    <li>Recompute weights and similarity score for the newfound setting using the ideal training kernel found at poin <i>b</i>;</li>\n",
    "                    <li>Compute accuracy, precision and recall (<i>classification</i>) or average error and variance (<i>regression</i>) for the selected setting against the sampling test set;</li>\n",
    "                    <li>Store these value, decorated with configuration and alignment for this dictionary;</li>\n",
    "                </ol>\n",
    "            </li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>For each sample round, sum all the alignment values related to the same kernel parameters in order to find the configuration that best behaved, keeping the dictionary within a list separated;</li>\n",
    "    <li>Try the configurations (one per dictionary) against the outer test set, compute accuracy, precision and recall (<i>classification</i>) or average error and variance (<i>regression</i>)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Approach Setting\n",
    "\n",
    "Kernel used:\n",
    "    \n",
    "<ul>\n",
    "    <li>Gaussian: $\\hspace{4mm}K_{\\sigma}(x_i, x) = e^{\\,-\\,\\left(\\frac{||x_i \\, - \\, x||^2}{2\\sigma}\\right)}$</li>\n",
    "    <li>Linear: $\\hspace{9mm}K(x_i, x) = x_i \\cdot x^T$</li>\n",
    "    <li>Polynomial: $\\hspace{1mm}K_d(x_i, x) = (1 +  x_i \\cdot x^t)^d$</li>\n",
    "    <li>Laplacian: $\\hspace{3mm}K_{\\gamma}(x_i, x) = e^{\\,-\\,(\\, \\gamma \\, ||x_i \\, - \\, x||_1)}$</li>\n",
    "    <li>Sigmoid: $\\hspace{5mm}K_{\\gamma}(x_i, x) = \\tanh \\,(\\,\\gamma \\, \\langle X, Y \\rangle + 1)$</li>\n",
    "</ul>\n",
    "\n",
    "The basical approach exploited has been picking three different kernels and applying them to every dataset, getting back 9 kernel matrices. Several combinations of three data preprocessing methods (Data origin centering, Data Normalization, Kernel Normalization) have been tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Toy Testing\n",
    "\n",
    "In order to analyze the correctness of the algorithm implemented three synthetic datasets have been generated and the algorithm have been launched over them.\n",
    "\n",
    "\n",
    "#### 7.1 Toy Dataset Generation\n",
    "\n",
    "For dataset generation we used the sklearn.datasets.make_classification function [4], initialized with the following configuration:\n",
    "\n",
    "<ul>\n",
    "    <li>n_samples = 300</li>\n",
    "    <li>n_features = 30</li>\n",
    "    <li>n_informative = 10</li>\n",
    "    <li>n_redundant = 0</li>\n",
    "    <li>n_classes = 2</li>\n",
    "</ul>\n",
    "\n",
    "The data gathered in this way have been splitted in three datasets and the informative variables have been distributed evenly between the first two. This procedure let us to check if the algorithm is able or not to percieve the irrelevance of the third dataset.\n",
    "\n",
    "Then, the three datasets have been splitted in training and test sets exploiting sklearn.model_selection.StratifiedShuffleSplit [5]. The initialization in the next\n",
    "\n",
    "<ul>\n",
    "    <li>n_splits = 1</li>\n",
    "    <li>test_size = 0.25</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "#### 7.2 Performances over Toy\n",
    "\n",
    "In the next the results achieved using the Toy datasets are shown. In particular, they are compared with the learning performances got studying one single dataset (the first one) using common learning algorithm, e.g., Logistic Regression and SVM.\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th> \n",
    "          <p><font  color=\"red\">Based on CA</font></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Cardio configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio test\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Accuracy</font></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Dementia configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia test\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.7<br>\n",
    "            Polynomial : 7, 2, 2<br>\n",
    "            Gaussian: 0.3, 0.3, 0.6\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8140113798008535<br>\n",
    "            Precision: 0.7804878048780488<br>\n",
    "            Recall: 0.8648648648648649\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.21867020939197357<br>\n",
    "            Accuracy: 0.8483169129720854<br>\n",
    "            Precision: 0.8315456327135972<br>\n",
    "            Recall: 0.8690476190476191\n",
    "        </td>\n",
    "        <td>\n",
    "            [1.37635178e-06, 9.93310800e-02, 9.70133466e-03, 6.67864067e-01, 4.38510115e-02, -7.36256679e-01]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.7<br>\n",
    "            Polynomial : 2, 2, 7<br>\n",
    "            Gaussian: 0.3, 0.3, 0.6\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8275248933143671<br>\n",
    "            Precision: 0.7857142857142857<br>\n",
    "            Recall: 0.8918918918918919\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.2320201774307744<br>\n",
    "            Accuracy: 0.8249178981937603<br>\n",
    "            Precision: 0.8088881826367921<br>\n",
    "            Recall: 0.8452380952380952\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.69048272, -0.40438296, 0.33601634, 0.23292882, 0.41944434, 0.12888623]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 1.3<br>\n",
    "            Sigmoid: 0.3, 0.2, 0.1<br>\n",
    "            Polynomial: 2, 3, 3<br>\n",
    "            Gaussian: 0.2, 0.3, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.7339971550497866<br>\n",
    "            Precision: 0.7073170731707317<br>\n",
    "            Recall: 0.7837837837837838\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.23112759419514883<br>\n",
    "            Accuracy: 0.8013136288998358<br>\n",
    "            Precision: 0.7902298850574713<br>\n",
    "            Recall: 0.8095238095238094\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.00387049, 0.0155308, 0.00115572, 0.00295326, 0.07049194, 0.00107543, 0.00713828, 0.99735214, 0.00110999]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.5<br>\n",
    "            Polynomial: 2, 7, 7<br>\n",
    "            Gaussian: 0.6, 0.6, 0.6\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8666429587482219<br>\n",
    "            Precision: 0.8684210526315785<br>\n",
    "            Recall: 0.8648648648646\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.21082589906567226<br>\n",
    "            Accuracy: 0.8364121510673236<br>\n",
    "            Precision: 0.8265773453945497<br>\n",
    "            Recall: 0.8452380952380952\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.28293068, 0.44627082, 0.14576441, 0.44132354, 0.55313343, 0.44589491]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "#### 7.3 Results discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Real Data\n",
    "\n",
    "In the next, the results achieved over the real data are shown and discussed. Again the comparison between the data integration approach and the shallow learning is proposed.\n",
    "\n",
    "\n",
    "#### 8.1 Performances\n",
    "\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on CA</font ></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Cardio configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio test\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 1.3<br>\n",
    "            Laplacian: 0.4, 0.9, 0.9<br>\n",
    "            Gaussian: 0.5, 1, 1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.4876963740600104<br>\n",
    "            Precision: 0.34516765285996054<br>\n",
    "            Recall: 0.7231404958677686\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.03207411722599631<br>\n",
    "            Accuracy: 0.5575231962332087<br>\n",
    "            Precision: 0.370735210200490<br>\n",
    "            Recall: 0.606425702811245\n",
    "        </td>\n",
    "        <td>\n",
    "            [-0.80895634, 0.2557566, 0.26466149, 0.26465771, 0.26465911, 0.26465895]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.9<br>\n",
    "            Sigmoid: 0.6, 0.6, 0.2<br>\n",
    "            Gaussian: 0.6, 0.3, 0.6\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5283299828754374<br>\n",
    "            Precision: 0.3825503355704698<br>\n",
    "            Recall: 0.47107438016528924\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.023241379530336285<br>\n",
    "            Accuracy: 0.48841919401744915<br>\n",
    "            Precision: 0.3147208168722621<br>\n",
    "            Recall: 0.6004016064257028\n",
    "        </td>\n",
    "        <td>\n",
    "            [-4.04835811e-11, 6.39532405e-01, -4.04835893e-11, 4.69236031e-01, -4.04835804e-11, 6.08946509e-01]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.5<br>\n",
    "            Sigmoid: 0.9, 0.9, 0.9<br>\n",
    "            Gaussian: 0.5, 1, 1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.49077693395875216<br>\n",
    "            Precision: 0.34829721362229105<br>\n",
    "            Recall: 0.9297520661157025\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.024054921569728476<br>\n",
    "            Accuracy: 0.58211581960024<br>\n",
    "            Precision: 0.39161162087370743<br>\n",
    "            Recall: 0.6345381526104418\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, -0.57734802, 0, -0.5773513, 0, -0.57735149]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.9<br>\n",
    "            Polynomial: 2, 2, 2<br>\n",
    "            Gaussian: 0.6, 0.6, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.48501600774328046<br>\n",
    "            Precision: 0.3414043583535109<br>\n",
    "            Recall: 0.5826446280991735\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.022394111162592222<br>\n",
    "            Accuracy: 0.500525088861192<br>\n",
    "            Precision: 0.3251298444956087<br>\n",
    "            Recall: 0.5020080321285141\n",
    "        </td>\n",
    "        <td>\n",
    "            [-0.00216869, -0.57733688, -0.00596827, -0.57733877, -0.00161064, -0.57733799]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on CA</font></p>\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia test\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.7<br>\n",
    "            Sigmoid: 0.2, 0.6, 0.6<br>\n",
    "            Gaussian: 0.3, 0.3, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5145762008507107<br>\n",
    "            Precision: 0.1783876500857633<br>\n",
    "            Recall: 0.8739495798319328\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.025238034586317307<br>\n",
    "            Accuracy: 0.5041506939854594<br>\n",
    "            Precision: 0.1744290781439166<br>\n",
    "            Recall: 0.7902621722846442\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.00000000e+00, -4.22882481e-01, -1.08259827e-16,  6.46392606e-01, 0.00000000e+00, 6.35096061e-01]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.5<br>\n",
    "            Sigmoid: 0.9, 0.4, 0.4<br>\n",
    "            Gaussian: 1, 0.5, 1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5296711277103434<br>\n",
    "            Precision: 0.1918238993710692<br>\n",
    "            Recall: 0.5126050420168067\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.026724874653312764<br>\n",
    "            Accuracy: 0.4997708746419916<br>\n",
    "            Precision: 0.1696459702387958<br>\n",
    "            Recall: 0.5430711610486891\n",
    "        </td>\n",
    "        <td>\n",
    "            [-3.76186696e-10, 5.70377232e-01, -3.76628319e-10, 5.80245771e-01, -3.76186694e-10, 5.81364480e-01]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.7<br>\n",
    "            Laplacian: 0.9, 0.4, 0.4<br>\n",
    "            Gaussian: 0.5, 1, 0.5\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5208527855586679<br>\n",
    "            Precision: 0.18006430868167203<br>\n",
    "            Recall: 0.9411764705882353\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.025731949505026247<br>\n",
    "            Accuracy: 0.5937959903062349<br>\n",
    "            Precision: 0.21972420698129522<br>\n",
    "            Recall: 0.7303370786516853\n",
    "        </td>\n",
    "        <td>\n",
    "            [-0.40824829, -0.40825135, -0.40824791, -0.40824741, -0.40824731, -0.40824747]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.5<br>\n",
    "            Polynomial: 2, 7, 7<br>\n",
    "            Gaussian: 0.6, 0.3, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.48646125116713346<br>\n",
    "            Precision: 0.16621253405994552<br>\n",
    "            Recall: 0.5126050420168067\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.02512163251299737<br>\n",
    "            Accuracy: 0.5154571491517955<br>\n",
    "            Precision: 0.18188049096731554<br>\n",
    "            Recall: 0.543071161048689\n",
    "        </td>\n",
    "        <td>\n",
    "            [-0.00255566, -0.57702685, -0.03326846, -0.57702322, -0.00376406, -0.57702403]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Accuracy</font></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Cardio configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio test\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 1.3<br>\n",
    "            Linear: -<br>\n",
    "            Gaussian: 0.3, 0.6, 0.6\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.53740443386484<br>\n",
    "            Precision: 0.69340974212034384<br>\n",
    "            Recall: 0.54077253212034384\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0.025411941604895932<br>\n",
    "            Accuracy: 0.5351351041379944<br>\n",
    "            Precision: 0.38918226446830567<br>\n",
    "            Recall: 0.33134920634920634\n",
    "        </td>\n",
    "        <td>\n",
    "            [-1.82364335e-01, -2.09411395e-04, -9.83230958e-01, -2.09400783e-04, -5.91624351e-08, -2.09398176e-04]*\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.7<br>\n",
    "            Polynomial: 5, 3, 3<br>\n",
    "            Gaussian: 0.5, 0.5, 1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.6064102928497666<br>\n",
    "            Precision: 0.43137254901960786<br>\n",
    "            Recall: 0.6609442060085837\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.022862124927406354<br>\n",
    "            Accuracy: 0.5194857326360217<br>\n",
    "            Precision: 0.3415364884671758<br>\n",
    "            Recall: 0.6150793650793651\n",
    "        </td>\n",
    "        <td>\n",
    "            [9.99997211e-01, 7.87108913e-04, -7.21686219e-04, 1.48091632e-03, -9.39626147e-05, 1.49520357e-03]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.5<br>\n",
    "            Sigmoid: 0.6, 0.2, 0.2<br>\n",
    "            Gaussian: 0.3, 0.3, 0.6\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5272108843537415<br>\n",
    "            Precision: 0.3716216216216216<br>\n",
    "            Recall: 0.8979591836734694\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.02453613516429783<br>\n",
    "            Accuracy: 0.621903852276345<br>\n",
    "            Precision: 0.42268894019014386<br>\n",
    "            Recall: 0.6888888888888888\n",
    "        </td>\n",
    "        <td>\n",
    "            [ 0, -0.57741441, 0, -0.57732454, 0, -0.57731185]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.7<br>\n",
    "            Sigmoid: 0.6, 0.2, 0.2<br>\n",
    "            Gaussian: 0.3, 0.3, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.52717687074829932<br>\n",
    "            Precision: 0.6612903225806452<br>\n",
    "            Recall: 0.4857142857142858\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.028289233641315092<br>\n",
    "            Accuracy: 0.5464762235535875<br>\n",
    "            Precision: 0.36338722125747674<br>\n",
    "            Recall: 0.5494949494949496\n",
    "        </td>\n",
    "        <td>\n",
    "            [0,  0.57739099, 0, 0.57733643, 0, 0.57732339]*\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Accuracy</font></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Dementia configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia test\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 1.3<br>\n",
    "            Laplacian: 0.4, 0.9, 0.4<br>\n",
    "            Gaussian: 1, 1, 0.5\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.49921840629767955<br>\n",
    "            Precision: 0.34791252485089463<br>\n",
    "            Recall: 0.7322175732217573\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.03306303924104954<br>\n",
    "            Accuracy: 0.5441536259982459<br>\n",
    "            Precision: 0.3671488308585083<br>\n",
    "            Recall: 0.5040160642570282\n",
    "        </td>\n",
    "        <td>\n",
    "            [-0.82520508, 0.25346384, 0.25237393, 0.25236869, 0.25242335, 0.25237385]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalization\n",
    "        </th>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "        <td>\n",
    "            v\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "#### 8.2 Results discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 Further considerations and studies\n",
    "\n",
    "From the Section 8 has been inferred the with high probability the most (and only!) meaningful dataset for the project purposes (see Section 1) is the clinical one. Because of this an interesting study could have been the one which applies a multi-kernel learning procedure only to such dataset. This kind of approach let the realization of multiple points of view (one per kernel) of the same object, i.e., the clinical dataset. Thus, the wider overall vision of the data got could provide a better comprehension of the correlation existing between the data and the diseases.\n",
    "\n",
    "\n",
    "#### 9.1 MKL over the Clinical dataset\n",
    "\n",
    "The study has been realized applying an MKL procedure to the Clinical dataset. The kernels used are all the ones listed in Section 6. In the next the performances.\n",
    "\n",
    "\n",
    "#### 9.2 Results discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Shallow regression\n",
    "\n",
    "Once enlightened as the most (and only) relevant dataset for dementia and cardiovascular failures, the Clinical one has been exploited for regression purposes. The regressive learning has the goal to predict the age at which the diesease will arise.\n",
    "The regression algorithm adopted are Lasso and SVM. In the next the performances and their discussion.\n",
    "\n",
    "\n",
    "#### 10.1 Shallow regression performances\n",
    "\n",
    "\n",
    "\n",
    "#### 10.2 Results discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 Conclusions and further possible studies\n",
    "\n",
    "In this section is presented a summarization of the results that have been obtained during the study presented above. Further possible study are suggested. Most of the ideas have not been tested largely due to computational limits of the authors.\n",
    "\n",
    "\n",
    "#### 11.1 What has been learned\n",
    "\n",
    "\n",
    "#### 11.2 Best configurations\n",
    "\n",
    "\n",
    "#### 11.3 Suggested further studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] Corinna Cortes, Mehryar Mohri, and Rostamizadeh Afshin. \"Two-stage learning kernel algorithms\", In Proceedings of the 27th International Conference on Machine Learning.<br>\n",
    "[2] https://en.wikipedia.org/wiki/Proximal_gradient_methods_for_learning<br>\n",
    "[3] Combettes, Patrick L.; Wajs, Valérie R. (2005). \"Signal Recovering by Proximal Forward-Backward Splitting\", Multiscale Model, Simul 4 (4): 1168–1200. doi:10.1137/050626090<br>\n",
    "[4] http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html<br>\n",
    "[5] http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
