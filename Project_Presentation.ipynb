{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:\"AMS\"}}});"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:\"AMS\"}}});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCB Final Project - a.y. 17/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i>Fiaschi Lorenzo, Franco Danilo</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol> <b>TODO</b>\n",
    "    <li><strike>problem presentation (dataset, objectives)</strike></li>\n",
    "    <li><strike>preprocessing</strike></li>\n",
    "    <li><strike>mkl procedure overview</strike></li>\n",
    "    <li><strike>chosen model description (alignment model, cortes approach)</strike></li>\n",
    "    <li><strike>algorithm pipeline (with a major point in the cross-validation decisions, how it is shuffled...)</strike></li>\n",
    "    <li><strike>approach settings</strike></li>\n",
    "    <li>performances over toy (with description on how it is generated</li>\n",
    "    <li>integration needed? comparison with single dataset model</li>\n",
    "    <li>performances over real dataset</li>\n",
    "    <li>integration needed? comparison with single dataset model</li>\n",
    "    <li>what we can learn from the best configuration (sparsity)</li>\n",
    "    <li>kernel integration on the only meaningful dataset (clinical)</li>\n",
    "    <li>overview on the regression approach</li>\n",
    "    <li>regression performances with data integration</li>\n",
    "    <li>single kernel approach after regression results</li>\n",
    "    <li>final comments over the results</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Problem\n",
    "The dataset consists of 2741 aligned patients affected by Diabetes; it is structured in 3 differents tables:\n",
    "<ol>\n",
    "    <li><b>Genetic Features</b>, 347 - Related to the SNP of 344 genes + 3 composite genes scores [blood pressure, alzheimer, CVD]</li>\n",
    "    <li><b>Retina's Features</b>, 157 - Engineered features extracted from patients' retinas</li>\n",
    "    <li><b>Clinical Features</b>, 15 - General patients' information</li>\n",
    "</ol>\n",
    "The objective of the study is to find a model that is able to predict whether a patient will incurr in either cardiovascular failures or in episodes of dementia.\n",
    "In the positive case, it is also aked to predict at which age this episodes will occurr.\n",
    "In order to learn such model, the output dataset has been provided; it is composed by two information, both for the occurrence of a cardiovascular failure and for the dementia episode: whether the episode has happened or not and at what age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing\n",
    "In order to be fed, the tables have been cleaned as follows:\n",
    "<ul>\n",
    "    <li>\n",
    "        <b><i>NaN Filling</i></b>: \n",
    "        <ul>\n",
    "            <li>\n",
    "                Clinical DS: \n",
    "                <ul>\n",
    "                    <li>\n",
    "                        [\"therapy\",\"gender\",\"precedent CVD\", \"smoker\"] $\\rightarrow$ most frequent;\n",
    "                    </li>\n",
    "                    <li>\n",
    "                        Others $\\rightarrow$ mean.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            <li>\n",
    "                Genetic DS: \n",
    "                <ul>\n",
    "                    <li>\n",
    "                        [composite gene scores] $\\rightarrow$ mean;\n",
    "                    </li>\n",
    "                    <li>\n",
    "                        Others $\\rightarrow$ min.\n",
    "                    </li>\n",
    "                </ul>\n",
    "            <li>\n",
    "                Vampire DS: \n",
    "                <ul>\n",
    "                    <li>\n",
    "                        All $\\rightarrow$ mean.\n",
    "                    </li>\n",
    "                </ul>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <b><i>One-Hot Encoding</i></b>:\n",
    "        <ul>\n",
    "            <li>Clinical DS:\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        \"therapy\" and \"Apoe4Presence\".\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b><i>Boolean: from binary to symmetric</i></b>: \n",
    "        <ul>\n",
    "            <li>Clinical DS:\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        [\"gender\",\"precedent CVD\", \"smoker\"] $\\rightarrow$ from [0,1] to [-1,1].\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "            <li>Outputs:\n",
    "                <ul>\n",
    "                    <li>\n",
    "                        [\"cvd_fail\",\"dement_fail\"] $\\rightarrow$ from [0,1] to [-1,1].\n",
    "                    </li>\n",
    "                </ul>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multiple Kernel Learning\n",
    "<b>Multiple Kernel Learning</b> refers to a set of machine learning methods that use a predefined set of kernels and learn an optimal linear or non-linear combination of kernels as part of the algorithm.<br>\n",
    "Reasons to use multiple kernel learning include:\n",
    "<ul>\n",
    "    <li>the ability to select for an optimal kernel and parameters from a larger set of kernels, reducing bias due to kernel selection while allowing for more automated machine learning methods;\n",
    "    </li>\n",
    "    <li>combining data from different sources (e.g. sound and images from a video) that have different notions of similarity and thus require different kernels;\n",
    "    </li>\n",
    "</ul>\n",
    "<img src='others/mkl.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The Model\n",
    "<ul>\n",
    "    <li><b><i>Target Function</i></b> $\\rightarrow$ Similarity-based function; it uses a similarity metric between the combined kernel matrix and an optimum kernel matrix calculated from the training data, in order to select the combination function parameters that maximize the similarity. The similarity between two kernel matrices can be calculated using kernel alignment, Euclidean distance, Kullback-Leibler (KL) divergence, or any other similarity measure.\n",
    "    </li>\n",
    "    <li><b><i>Training Method</i></b> $\\rightarrow$ One-step method; it calculates both the combination function parameters and the parameters of the combined base learner in a single pass. One can use a sequential approach or a simultaneous approach. In the sequential approach, the combination function parameters are determined first, and then a kernel-based learner is trained using the combined kernel. In the simultaneous approach, both set of parameters are learned together.\n",
    "    </li>\n",
    "</ul>\n",
    "The chosen algorithm is called <i>Centered-kernel alignment</i> [1] and its main purpose is to compute a set of $P$ kernels $K_i$, $i \\, = \\, 1...P$ from the datasets and to use a linear combination of them to approximate an ideal kernel. Then the obtained approximated kernel can be used for both classification and regression purposes. The functional is:<br>\n",
    "\n",
    "\\begin{equation}\n",
    "\\max\\limits_{\\eta \\in \\mathcal{M}} CA(K_{\\eta}, IK)\n",
    "\\label{eq:problem}\n",
    "\\end{equation}\n",
    "\n",
    "where $IK = y^T y$ is the ideal kernel, $K_{\\eta} = \\sum\\limits_{i=1}^P K_i \\eta_i$ is its approximation and $\\mathcal{M}=\\{\\eta : ||\\eta||_2 = 1\\}$ imposing $\\eta$ being a unit norm vector. In turn, $CA(K_1, K_2)$ is defined as\n",
    "\n",
    "\\begin{equation*}\n",
    "CA(K_1^c, K_2^c) = \\frac{\\langle K_1^c, K_2^c \\rangle_F}{\\sqrt{\\langle K_1^c, K_1^c\\rangle_F \\; \\langle K_2^c, K_2^c \\rangle_F}}\n",
    "\\end{equation*}\n",
    "\n",
    "with $K^c$ is the centered version of $K$ and can be calculated as\n",
    "\n",
    "\\begin{equation*}\n",
    "K^c = K - \\frac{1}{N} 11^TK - \\frac{1}{N} K11^T + \\frac{1}{N^2} \\left(1^TK1\\right)11^T\n",
    "\\end{equation*}\n",
    "\n",
    "where $1$ is the vector of ones with proper dimension.\n",
    "\n",
    "The optimization problem \\eqref{eq:problem} has then a unique analytical solution\n",
    "\n",
    "\\begin{equation}\n",
    "\\eta = \\frac{M^{-1}a}{||M^{-1}a||_2}\n",
    "\\label{eq:problem_solution}\n",
    "\\end{equation}\n",
    "\n",
    "where $M = \\{\\langle K_m, K_h\\rangle_F\\}_{m,h \\, = \\, 1}^P$ and $a = \\{\\langle K_m, IK\\rangle_F\\}_{m \\, = \\, 1}^P$.\n",
    "\n",
    "In order to avoid overfitting, to be more robust in the learning procedure and in order to get deeper insights of the problem we added either an $L_1$ or $L_2$ penalty to the functional \\eqref{eq:problem}, obtaining the following two reformulations\n",
    "\n",
    "\\begin{equation}\n",
    "\\max\\limits_{\\eta \\in \\mathcal{M}} CA(K_{\\eta}, IK) - \\lambda \\, ||\\eta||_2^2 \\;\\; (a), \\qquad \\max\\limits_{\\eta \\in \\mathcal{M}} CA(K_{\\eta}, IK) - c \\, ||\\eta||_1 \\;\\; (b).\n",
    "\\label{eq:problem_penalty}\n",
    "\\end{equation}\n",
    "\n",
    "While the Equation \\eqref{eq:problem_penalty}(a) has the unique analytical solution \n",
    "\n",
    "\\begin{equation}\n",
    "\\eta = \\frac{(M-\\lambda I)^{-1}a}{||(M-\\lambda I)^{-1}a||_2}\n",
    "\\label{eq:problem_solution_lambda}\n",
    "\\end{equation}\n",
    "\n",
    "Equation \\eqref{eq:problem_penalty}(b) does not due to the non-differentiability of the $L_1$ norm. To converge to the optimum we applied the forward-backward splitting method [2][3]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. The Algorithm\n",
    "\n",
    "<ol>\n",
    "    <li><i>Datasets loading</i> $\\rightarrow$ (Clinical, Genetic, Vampire, Outputs);</li>\n",
    "    <li><i>Outer split</i> $\\rightarrow$ 75% training + 25% test for final testing purposes;</li>\n",
    "    <li><i>Kernel definition</i> $\\rightarrow$ dictionary list: [{<b>kernelType1:[parameter list]</b>, <b>kernelType2:[parameter list]</b>, <b>...</b> }, <b>...</b> ] </li>\n",
    "    <li><i>Sampling rounds</i> $\\rightarrow$ 3 rounds of 75% training + 25% mid test (extracted from the previous 75% of training) for statistical stability:\n",
    "        <ol>\n",
    "            <li>If stated, perform training matrix centering and/or normalisation;</li>\n",
    "            <li>For each dictionary configuration:\n",
    "                <ol>\n",
    "                    <li>Build the ideal kernel from the training outputs;</li>\n",
    "                    <li>Build all the possible combination between the kernels parameters;</li>\n",
    "                    <li>3-Fold cross validation over the 75% sampling training:\n",
    "                        <ol>\n",
    "                            <li>Build the ideal kernel matrices from both training and validation output sets;</li>\n",
    "                            <li>For each configurations:\n",
    "                                <ol>\n",
    "                                    <li>Compute all the kernel matrices for that configuration;</li>\n",
    "                                    <li>Find the optimal weights for those kernel matrices using the ideal training kernel;</li>\n",
    "                                    <li>Compute the weighted sum of the kernel matrices;</li>\n",
    "                                    <li>Compare the obtained matrix with the ideal validation kernel using the Cortes Alignment metric and store this similarity measure;</li>\n",
    "                                </ol>\n",
    "                            </li>\n",
    "                        </ol>                       \n",
    "                    </li>\n",
    "                    <li>Find the configuration with greatest mean across the three validation fold;</li>\n",
    "                    <li>Recompute weights and similarity score for the newfound setting using the ideal training kernel found at poin <i>a</i>;</li>\n",
    "                    <li>Compute accuracy, precision and recall for the selected setting against the sampling test set;</li>\n",
    "                    <li>Store these value, decorated with configuration and alignment for this dictionary;</li>\n",
    "                </ol>\n",
    "            </li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>For each sample round, sum all the alignment values related to the same kernel parameters in order to find the configuration that best behaved, keeping the dictionary within a list separated;</li>\n",
    "    <li>Try the configurations (one per dictionary) against the outer test set, compute accuracy, precision and recall</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Approach Setting\n",
    "\n",
    "Kernel used:\n",
    "    \n",
    "<ul>\n",
    "    <li>Gaussian: $\\hspace{4mm}K_{\\sigma}(x_i, x) = e^{\\,-\\,\\left(\\frac{||x_i \\, - \\, x||^2}{2\\sigma}\\right)}$</li>\n",
    "    <li>Linear: $\\hspace{9mm}K(x_i, x) = x_i \\cdot x^T$</li>\n",
    "    <li>Polynomial: $\\hspace{1mm}K_d(x_i, x) = (1 +  x_i \\cdot x^t)^d$</li>\n",
    "    <li>Laplacian: $\\hspace{3mm}K_{\\gamma}(x_i, x) = e^{\\,-\\,(\\, \\gamma \\, ||x_i \\, - \\, x||_1)}$</li>\n",
    "    <li>Sigmoid: $\\hspace{5mm}K_{\\gamma}(x_i, x) = \\tanh \\,(\\,\\gamma \\, \\langle x_i, x \\rangle + 1)$</li>\n",
    "</ul>\n",
    "\n",
    "The basical approach exploited has been picking three different kernels and applying them to every dataset, getting back 9 kernel matrices. Several combinations of three data preprocessing methods (Data origin centering, Data Normalization, Kernel Normalization) have been tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Toy Testing\n",
    "\n",
    "In order to analyze the correctness of the algorithm implemented three synthetic datasets have been generated and the algorithm have been launched over them.\n",
    "\n",
    "\n",
    "#### 7.1 Toy Dataset Generation\n",
    "\n",
    "For dataset generation we used the sklearn.datasets.make_classification function [4], initialized with the following configuration:\n",
    "\n",
    "<ul>\n",
    "    <li>n_samples = 300</li>\n",
    "    <li>n_features = 30</li>\n",
    "    <li>n_informative = 10</li>\n",
    "    <li>n_redundant = 0</li>\n",
    "    <li>n_classes = 2</li>\n",
    "</ul>\n",
    "\n",
    "The data gathered in this way have been splitted in three datasets and the informative variables have been distributed evenly between the first two. This procedure let us to check if the algorithm is able or not to percieve the irrelevance of the third dataset.\n",
    "\n",
    "Then, the three datasets have been splitted in training and test sets exploiting sklearn.model_selection.StratifiedShuffleSplit [5]. The initialization in the next\n",
    "\n",
    "<ul>\n",
    "    <li>n_splits = 1</li>\n",
    "    <li>test_size = 0.25</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "#### 7.2 Performances over Toy\n",
    "\n",
    "##### 7.1.1 MKL\n",
    "\n",
    "In the next the results achieved using the Toy datasets are shown. In particular, they are compared with the learning performances got studying one single dataset (the first one) using common learning algorithm, e.g., Logistic Regression and SVM.\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th> \n",
    "          <p><font  color=\"red\">Based on CA</font></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Test\n",
    "        </th>\n",
    "        <th>\n",
    "          Train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 1.3<br>\n",
    "            Laplacian : 0.2, 0.6, 0.2<br>\n",
    "            Gaussian: 0.3, 0.3, 0.6\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8549<br>\n",
    "            Precision: 0.7826<br>\n",
    "            Recall: 0.9730\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.2187<br>\n",
    "            Accuracy: 0.84832<br>\n",
    "            Precision: 0.8315<br>\n",
    "            Recall: 0.86905\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.11894472, -0.10650123, -0.58678192, 0.38271258,  0.64068699, -0.27064346]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.7<br>\n",
    "            Polynomial : 2, 2, 7<br>\n",
    "            Gaussian: 0.3, 0.3, 0.6\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8275<br>\n",
    "            Precision: 0.7857<br>\n",
    "            Recall: 0.8919\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.2029<br>\n",
    "            Accuracy: 0.8186<br>\n",
    "            Precision: 0.8213<br>\n",
    "            Recall: 0.8095\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.69048272, -0.40438296, 0.33601634, 0.23292882, 0.41944434, 0.12888623]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.5<br>\n",
    "            Linear : -<br>\n",
    "            Gaussian: 0.3, 0.3, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8410<br>\n",
    "            Precision: 0.7907<br>\n",
    "            Recall: 0.9189\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.2448<br>\n",
    "            Accuracy: 0.8130<br>\n",
    "            Precision: 0.8051<br>\n",
    "            Recall: 0.8214\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.15587906, 0.00148777, 0.27568084, 0.00145643, 0.94852263, 0.00151153]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.5<br>\n",
    "            Polynomial: 3, 3, 3<br>\n",
    "            Gaussian: 0.5, 0.5, 0.1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8937<br>\n",
    "            Precision: 0.87188<br>\n",
    "            Recall: 0.9189\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.2430<br>\n",
    "            Accuracy: 0.7545<br>\n",
    "            Precision: 0.7458<br>\n",
    "            Recall: 0.7619\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.25203873, 0.44604029, 0.25542251, 0.44868187, 0.51932414, 0.44863225]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Accuracy</font></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Test\n",
    "        </th>\n",
    "        <th>\n",
    "          Train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 1.3<br>\n",
    "            Linear: -<br>\n",
    "            Polynomial : 2, 2, 2<br>\n",
    "            Gaussian: 0.1, 0.1, 0.5\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8670<br>\n",
    "            Precision: 0.8462<br>\n",
    "            Recall: 0.8649\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.2213<br>\n",
    "            Accuracy: 0.7779<br>\n",
    "            Precision: 0.7675<br>\n",
    "            Recall: 0.7857\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.04692887, -0.06199509, -0.53220357, 0.01056036, -0.02753925, 0.82368748, 0.018547, 0.07773182,  0.15810262]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.7<br>\n",
    "            Linear: -<br>\n",
    "            Polynomial : 2, 2, 2<br>\n",
    "            Gaussian: 0.5, 0.1, 0.7\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8538<br>\n",
    "            Precision: 0.8250<br>\n",
    "            Recall: 0.8919\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.2175<br>\n",
    "            Accuracy: 0.7956<br>\n",
    "            Precision: 0.7810<br>\n",
    "            Recall: 0.8095\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.33429467, -0.17592443, -0.39955222, 0.15408311, -0.10726992, 0.10759013, 0.07914564,  0.71947001,  0.35627305]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.9<br>\n",
    "            Linear: -<br>\n",
    "            Gaussian: 0.3, 0.6, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8535<br>\n",
    "            Precision: 0.8421<br>\n",
    "            Recall: 0.8649\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.2086<br>\n",
    "            Accuracy: 0.8013<br>\n",
    "            Precision: 0.7911<br>\n",
    "            Recall: 0.8095\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.18207216, 0.00148136, 0.26428069, 0.00133108, 0.94710043, 0.00150188]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.5<br>\n",
    "            Sigmoid: 0.4, 0.9, 0.4<br>\n",
    "            Gaussian: 0.5, 0.5, 1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.8403<br>\n",
    "            Precision: 0.8205<br>\n",
    "            Recall: 0.8649\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.2144<br>\n",
    "            Accuracy: 0.8424<br>\n",
    "            Precision: 0.8346<br>\n",
    "            Recall: 0.8571\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.28083217, 0.457611, 0.25571453, 0.46127277, 0.47375624, 0.45729422]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "##### 7.1.2 L1 Logistic Regression\n",
    "<br>\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Logistic Regression</font ></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Best Lambda\n",
    "        </th>\n",
    "        <th>\n",
    "          Test\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L1 - Centering - $\\;\\;$ Normalizing</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            0.1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5473<br>\n",
    "            Precision: 0.5366<br>\n",
    "            Recall: 0.5946\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, 0, 0, 0, 0, 0, 0.70943101, 0, 0, 0]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L1 - Centering</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            1.9\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5473<br>\n",
    "            Precision: 0.5366<br>\n",
    "            Recall: 0.5946\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, 0, 0, 0, 0, 0, 0.70943101, 0, 0, 0]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Results discussion\n",
    "\n",
    "Some considerations can be made out of the results:\n",
    "<ul>\n",
    "    <li>it seems to be some performances improvements using an approach based on the CA rather than one based on the accuracy;</li>\n",
    "    <li>the results obtained using kernel normalisation approaches are generally comparable, in term of accuracy, with the one achieved by the normalisation procedure usage;</li>\n",
    "    <li>the selected kernels are generally belonging to the set K = {Linear, Polynomial};</li>\n",
    "    <li>even if the informative features are not evenly distributed among the datasets (in particulare none of them is in the third one), looking at the $\\eta$ coefficients, the algorithm seems not to see it. Indeed the coefficients magnitudes, kernel-wise, are generally comparable (also in the best performances);</li>\n",
    "    <li>compared with the shallow learning realized on only the first dataset, MKL's performances are notably higher. This is in line with the fact that such dataset contains only the 70% of the global, useful information.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Real Data\n",
    "\n",
    "In the next, the results achieved over the real data are shown and discussed. Again the comparison between the data integration approach and the shallow learning is proposed.\n",
    "\n",
    "\n",
    "#### 8.1 Performances \n",
    "\n",
    "##### 8.1.1 MKL\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on CA</font ></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Cardio configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio test\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 1.3<br>\n",
    "            Linear: - <br>\n",
    "            Gaussian: 0.3, 0.6, 0.6\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5142<br>\n",
    "            Precision: 0.3453<br>\n",
    "            Recall: 0.5044\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0221<br>\n",
    "            Accuracy: 0.5173<br>\n",
    "            Precision: 0.3763<br>\n",
    "            Recall: 0.1834\n",
    "        </td>\n",
    "        <td>\n",
    "            [1.53594173e-01, 2.05124331e-04, 9.88133950e-01, 2.05128456e-04, 6.19603791e-08, 2.05128150e-04]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.7<br>\n",
    "            Polynomial: 5, 3, 5<br>\n",
    "            Gaussian: 1, 1, 1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.6336<br>\n",
    "            Precision: 0.4486<br>\n",
    "            Recall: 0.6886\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0219<br>\n",
    "            Accuracy: 0.5151<br>\n",
    "            Precision: 0.3496<br>\n",
    "            Recall: 0.4438\n",
    "        </td>\n",
    "        <td>\n",
    "            [9.99995428e-01, 1.55040582e-03, 4.85827949e-04, 1.73244483e-03, -7.08555105e-04, 1.73244188e-03]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.9<br>\n",
    "            Polynomial: 7, 7, 2<br>\n",
    "            Gaussian: 0.3, 0.3, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5172<br>\n",
    "            Precision: 0.3534<br>\n",
    "            Recall: 0.3857\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0184<br>\n",
    "            Accuracy: 0.5751<br>\n",
    "            Precision: 0.3904<br>\n",
    "            Recall: 0.6391\n",
    "        </td>\n",
    "        <td>\n",
    "            [8.61000942e-09, 5.92773226e-25, 2.09550805e-23, 5.92772271e-25, 1.00000000e+00, 5.92772251e-25]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.9<br>\n",
    "            Polynomial: 5, 3, 3<br>\n",
    "            Gaussian: 0.5, 1, 0.5\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5523<br>\n",
    "            Precision: 0.3911<br>\n",
    "            Recall: 0.4649\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0214<br>\n",
    "            Accuracy: 0.5059<br>\n",
    "            Precision: 0.3522<br>\n",
    "            Recall: 0.1538\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.00423997, 0.57731552, 0.00998617, 0.57731614, -0.00111829, 0.57731613]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on CA</font></p>\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia test\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.9<br>\n",
    "            Polynomial: 2, 7, 7<br>\n",
    "            Gaussian: 0.3, 0.3, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5016<br>\n",
    "            Precision: 0.25<br>\n",
    "            Recall: 0.0084\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0196<br>\n",
    "            Accuracy: 0.5292<br>\n",
    "            Precision: 0.2273<br>\n",
    "            Recall: 0.3408\n",
    "        </td>\n",
    "        <td>\n",
    "            [5.27925090e-51, 0.00000000e+00, 1.31633288e-53, 4.87947698e-56, 1.00000000e+00, 4.87947064e-56]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.7<br>\n",
    "            Polynomial: 3, 3, 3<br>\n",
    "            Gaussian: 0.5, 0.5, 0.5\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.6962<br>\n",
    "            Precision: 0.2825<br>\n",
    "            Recall: 0.8403\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0209<br>\n",
    "            Accuracy: 0.4751<br>\n",
    "            Precision: 0.1542<br>\n",
    "            Recall: 0.3745\n",
    "        </td>\n",
    "        <td>\n",
    "            [9.99980246e-01, -2.49677856e-03, 5.97825819e-04, -4.00966828e-03, -8.51582861e-04, -4.01427793e-03]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.7<br>\n",
    "            Linear: -<br>\n",
    "            Gaussian: 0.3, 0.6, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5017<br>\n",
    "            Precision: 0.18<br>\n",
    "            Recall: 0.0756\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0198<br>\n",
    "            Accuracy: 0.6351<br>\n",
    "            Precision: 0.2457<br>\n",
    "            Recall: 0.7566\n",
    "        </td>\n",
    "        <td>\n",
    "            [3.84334703e-09, 1.08289854e-11, 1.32260026e-09, 1.08289422e-11, 1.00000000e+00, 1.08289425e-11]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.5<br>\n",
    "            Polynomial: 2, 2, 2<br>\n",
    "            Gaussian: 0.6, 0.6, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5399<br>\n",
    "            Precision: 0.1965<br>\n",
    "            Recall: 0.5630\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0201<br>\n",
    "            Accuracy: 0.5170<br>\n",
    "            Precision: 0.1832<br>\n",
    "            Recall: 0.5131\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.00191554, 0.57733907, 0.00581971, 0.57733679, 0.00267856, 0.57733623]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Accuracy</font></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Cardio configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio test\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 1.3<br>\n",
    "            Polynomial: 7, 2, 2<br>\n",
    "            Gaussian: 0.3, 0.6, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5106<br>\n",
    "            Precision: 0.3680<br>\n",
    "            Recall: 0.4057\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0163<br>\n",
    "            Accuracy: 0.5612<br>\n",
    "            Precision: 0.3639<br>\n",
    "            Recall: 0.7030\n",
    "        </td>\n",
    "        <td>\n",
    "            [1.00000000e+00, 1.11659997e-27, 3.61028219e-27, 1.11655594e-27, 1.92671234e-14, 1.11654064e-27]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.9<br>\n",
    "            Polynomial: 5, 3, 3<br>\n",
    "            Gaussian: 0.5, 0.5, 1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.6089<br>\n",
    "            Precision: 0.4503<br>\n",
    "            Recall: 0.6680\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0204<br>\n",
    "            Accuracy: 0.5360<br>\n",
    "            Precision: 0.3565<br>\n",
    "            Recall: 0.4970\n",
    "        </td>\n",
    "        <td>\n",
    "            [9.99997666e-01, -9.75757165e-04, -1.48960098e-03, -8.54729364e-04, 4.36034115e-05, -8.73927921e-04]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 1.3<br>\n",
    "            Laplacian: 0.2, 0.2, 0.6<br>\n",
    "            Gaussian: 0.3, 0.3, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5385<br>\n",
    "            Precision: 0.3993<br>\n",
    "            Recall: 0.4549\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0198<br>\n",
    "            Accuracy: 0.5903<br>\n",
    "            Precision: 0.3956<br>\n",
    "            Recall: 0.6505\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.41148454, 0.40759869, 0.40763828, 0.40758741, 0.40758505, 0.40758035]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 1.3<br>\n",
    "            Laplacian: 0.6, 0.2, 0.2<br>\n",
    "            Gaussian: 0.6, 0.3, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5209<br>\n",
    "            Precision: 0.3754<br>\n",
    "            Recall: 0.5123\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0260<br>\n",
    "            Accuracy: 0.5408<br>\n",
    "            Precision: 0.3452br>\n",
    "            Recall: 0.7273\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.40824884, 0.40823975, 0.40826687, 0.40824452, 0.40825236, 0.4082374]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Accuracy</font></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Dementia configuration\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia test\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia train\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            Lambda: 0.5<br>\n",
    "            Sigmoid: 0.6, 0.2, 0.6 <br>\n",
    "            Gaussian: 0.3, 0.6, 0.6\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5011<br>\n",
    "            Precision: 0.1738<br>\n",
    "            Recall: 0.8824\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0229<br>\n",
    "            Accuracy: 0.5319<br>\n",
    "            Precision: 0.1885<br>\n",
    "            Recall: 0.8127\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.00000000e+00, -5.98992292e-01, 3.88679462e-07, 5.66845714e-01, 0.00000000e+00, 5.65591876e-01]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L2 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.5<br>\n",
    "            Polynomial: 5, 3, 3 <br>\n",
    "            Gaussian: 1, 0.5, 1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.6374<br>\n",
    "            Precision: 0.2479<br>\n",
    "            Recall: 0.7563\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0236<br>\n",
    "            Accuracy: 0.5368<br>\n",
    "            Precision: 0.1945<br>\n",
    "            Recall: 0.5543\n",
    "        </td>\n",
    "        <td>\n",
    "            [9.99997434e-01, 1.09082797e-03, -1.14841501e-03, 1.10519947e-03, 4.54430047e-04, 1.09300865e-03]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering - $\\;\\;$ Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.5<br>\n",
    "            Sigmoid: 0.6, 0.2, 0.2 <br>\n",
    "            Gaussian: 0.3, 0.3, 0.3\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5039<br>\n",
    "            Precision: 0.1829<br>\n",
    "            Recall: 0.1261\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.02304<br>\n",
    "            Accuracy: 0.6507<br>\n",
    "            Precision: 0.2544<br>\n",
    "            Recall: 0.7790\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, 0.57739941, 0, 0.57732492, 0, 0.57732647]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            L1 - Centering -$\\;$K Normalizing\n",
    "        </th>\n",
    "        <td>\n",
    "            Lambda: 0.5<br>\n",
    "            Sigmoid: 0.9, 0.4, 0.4 <br>\n",
    "            Gaussian: 0.5, 0.5, 1\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5421<br>\n",
    "            Precision: 0.1988<br>\n",
    "            Recall: 0.5462\n",
    "        </td>\n",
    "        <td>\n",
    "            CA: 0.0236<br>\n",
    "            Accuracy: 0.5682<br>\n",
    "            Precision: 0.2118<br>\n",
    "            Recall: 0.5356\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, 0.57735433, 0, 0.57734834, 0, 0.57734814]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br><br>\n",
    "\n",
    "##### 8.1.2 L1 Logistic Regression\n",
    "<br>\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Logistic Regression</font ></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Cardio Best Lambda\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio test\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L1 - Centering - $\\;\\;$ Normalizing</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            1.9\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5846<br>\n",
    "            Precision: 0.5755<br>\n",
    "            Recall: 0.2675\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.24295029, 0, 2.20323597, -0.75412797, 0.23335976, 0.52585566, 0, 0, 0.71051908, 2.84089014, -1.29482284, 2.3777739, -3.18657635, 8.22248962, 0, -0.10014134, 0, 0.51144475, 0.82023147, 0, 1.18526461]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L1 - Centering</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            1.9\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.6411<br>\n",
    "            Precision: 0.4723<br>\n",
    "            Recall: 0.6360\n",
    "        </td>\n",
    "        <td>\n",
    "            [0.24541592, 0, 2.20349362, -0.75647233,  0.23339294,  0.52580679, 0, 0, 0.71058628,  2.84110754, -1.29468123,  2.3778646, -3.18673149, 8.22266713, 0, -0.09714606, 0, 0.50942805, 0.81592509, 0, 1.18512638]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br>\n",
    "<br>\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Logistic Regression</font ></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Dementia Best Lambda\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia test\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L1 - Centering - $\\;\\;$ Normalizing</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            0.5\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.5049<br>\n",
    "            Precision: 0.3333<br>\n",
    "            Recall: 0.0168\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, 0, 0, -0.34944809, 0.47924946, -4.33491868, 0, 0, 1.68668473, 0, 0, 0, 0, -0.1756032, 0, 0, 0, 0, 0, 0]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L1 - Centering</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            0.5\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.6716<br>\n",
    "            Precision: 0.2758<br>\n",
    "            Recall: 0.7647\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, 0, 0, -0.34944809, 0.47924946, -4.33491868, 0, 0, 1.68668473, 0, 0, 0, 0, 0, -0.1756032, 0, 0, 0, 0, 0, 0,]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 Results discussion\n",
    "Some considerations can be made out of the results:\n",
    "<ul>\n",
    "    <li>it seems to be some performances improvements using an approach based on the CA rather than one based on the accuracy</li>\n",
    "    <li>the kernel normalisation approach gives better results in term of accuracy when compared to the others;</li>\n",
    "    <li>usually the approach based on the L2 penalization picks a Polynomial kernel;</li>\n",
    "    <li>the kernel normalisation provides always the best result when the functional is penalized with an L2-norm Tikhonov;</li>\n",
    "    <li>the selected kernel tends to belong to set K = {Laplacian, Sigmoid, Polynomial};</li>\n",
    "    <li>among the best performances, the Polynomial kernel is always selected and the clinical dataset is pointed out as the most informative; the latter is justified by the coefficient ($\\eta_1$) associated to such dataset once transformed by the Polynomial kernel. Indeed it is several orders of magnitude greater than the others coefficients;</li>\n",
    "    <li>due to the fact that the information is mainly contained in the clinical dataset, the performances achieved with a shallow classification are comparable with the ones got exploiting MKL.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 Further considerations and studies\n",
    "\n",
    "From the Section 8 has been inferred that with high probability the most (and only!) meaningful dataset for the project purposes (see Section 1) is the clinical one. Because of this an interesting study could have been the one which applies a multi-kernel learning procedure only to such dataset. This kind of approach let the realization of multiple points of view (one per used kernel) of the same object, i.e., the clinical dataset. Such procedure could provide a better comprehension of the correlation existing between the data and the diseases.\n",
    "\n",
    "\n",
    "#### 9.1 MKL over the Clinical dataset\n",
    "\n",
    "Looking at the results of Section 8, has been decided to generate the wider overall vision of the Clinical dataset exploiting the Polynomial kernel both along with the Gaussian one (again, but with a larger set of possible meta-parameters) and the other ones. In the next the performances.\n",
    "\n",
    "\n",
    "\n",
    "#### 9.2 Results discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Shallow regression\n",
    "\n",
    "Once selected as the most (and only) relevant dataset for dementia and cardiovascular failures, the Clinical one has been exploited for regression purposes. The regressive learning has the goal to predict the age at which the diesease will arise.\n",
    "The regression algorithm adopted are Lasso and SVM. In the next the performances and their discussion.\n",
    "\n",
    "\n",
    "#### 10.1 Shallow regression performances\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Lasso and SVM</font ></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Cardio Best Lambda\n",
    "        </th>\n",
    "        <th>\n",
    "          Cardio test\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L2 - Centering - $\\;\\;$ Normalizing</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            1.9\n",
    "        </td>\n",
    "        <td>\n",
    "            Average Error: 0.5846452922699763<br>\n",
    "            Error Variance: 0.575471698113207\n",
    "        </td>\n",
    "        <td>\n",
    "            -\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L2 - Centering</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            1.9\n",
    "        </td>\n",
    "        <td>\n",
    "            Accuracy: 0.6411265609438443<br>\n",
    "            Precision: 0.4723127035830619<br>\n",
    "            Recall: 0.6359649122807017\n",
    "        </td>\n",
    "        <td>\n",
    "            -\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L1 - Centering - $\\;\\;$ Normalizing</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            0.01\n",
    "        </td>\n",
    "        <td>\n",
    "            Average Error: 0.8382311045954134<br>\n",
    "            Error Variance: 0.11874280646397932\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, 0,  0, 0.14386508, 0.05589937, 0, 0, 0, 0.25778769  0, 0,  0, 0, 0.99383314, 0, 0, 0,  0, 0, 0, 0]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L1 - Centering</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            0.01\n",
    "        </td>\n",
    "        <td>\n",
    "            Average Error: 2.779940546323388<br>\n",
    "            Error Variance: 4.34040204773008\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, 0,  0, 0.14386508, 0.05589937, 0, 0, 0, 0.25778769  0, 0,  0, 0, 0.99383314, 0, 0, 0,  0, 0, 0, 0]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br>\n",
    "<br>\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <th>\n",
    "          <p><font  color=\"red\">Based on Lasso and SVM</font ></p>\n",
    "        </th>\n",
    "        <th align=\"justify\">\n",
    "          Dementia Best Lambda\n",
    "        </th>\n",
    "        <th>\n",
    "          Dementia test\n",
    "        </th>\n",
    "        <th>\n",
    "          Eta\n",
    "        </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L2 - Centering - $\\;\\;$ Normalizing</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            0.12\n",
    "        </td>\n",
    "        <td>\n",
    "            Average error: 0.6938040471139271<br>\n",
    "            Error variance: 0.711149051596936\n",
    "        </td>\n",
    "        <td>\n",
    "            -\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L2 - Centering</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            0.12\n",
    "        </td>\n",
    "        <td>\n",
    "            Average error: 0.6938040471139271<br>\n",
    "            Error variance: 0.711149051596936\n",
    "        </td>\n",
    "        <td>\n",
    "            -\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L1 - Centering - $\\;\\;$ Normalizing</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            0.5\n",
    "        </td>\n",
    "        <td>\n",
    "            Average error: 0.8432866613431059<br>\n",
    "            Error variance: 0.13348983190138347\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, 0, 0, -0.21727138  0.07391699, 0, 0, 0,  0.26572281, 0, 0, 0, 0, 1.20944333, 0, 0, 0, 0, 0, 0, 0]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>\n",
    "            <p>L1 - Centering</p>\n",
    "        </th>\n",
    "        <td align=\"left\">\n",
    "            0.5\n",
    "        </td>\n",
    "        <td>\n",
    "            Average error: 3.3485817029263245<br>\n",
    "            Error variance: 6.033243528951659\n",
    "        </td>\n",
    "        <td>\n",
    "            [0, 0, 0, -0.21727138  0.07391699, 0, 0, 0,  0.26572281, 0, 0, 0, 0, 1.20944333, 0, 0, 0, 0, 0, 0, 0]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "#### 10.2 Results discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 Conclusions and further possible studies\n",
    "\n",
    "In this section is presented a summarization of the results that have been obtained during the study presented above. Further possible study are suggested. Most of the ideas have not been tested largely due to computational limits of the authors.\n",
    "\n",
    "\n",
    "#### 11.1 What has been learned\n",
    "\n",
    "In the context of the Cortes Alignment, the Polynomial kernel usage seems to constantly provides higher performances<br>\n",
    "\n",
    "#### 11.2 Best configurations\n",
    "\n",
    "\n",
    "#### 11.3 Suggested further studies\n",
    "\n",
    "Preprocessing with filter methods<br>\n",
    "Configurations performance stability analysis<br>\n",
    "Configurations performance over different approaches analysis<br>\n",
    "Changing of the functional using a risk minimizator reather than a kernel aligner<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] Corinna Cortes, Mehryar Mohri, and Rostamizadeh Afshin (2010). \"Two-stage learning kernel algorithms\", In Proceedings of the 27th International Conference on Machine Learning.<br>\n",
    "[2] https://en.wikipedia.org/wiki/Proximal_gradient_methods_for_learning<br>\n",
    "[3] Combettes, Patrick L.; Wajs, Valrie R. (2005). \"Signal Recovering by Proximal Forward-Backward Splitting\", Multiscale Model, Simul 4 (4): 11681200. doi:10.1137/050626090<br>\n",
    "[4] http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html<br>\n",
    "[5] http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
