{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilo/.conda/envs/bcb/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import Utils as ut\n",
    "import CortesAlignmentFile as ca\n",
    "import mySampler as ms\n",
    " \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from threading import Thread, Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(os.path.join('data', 'toyDataset.csv')).values\n",
    "label = pd.read_csv(os.path.join('data', 'toyLabel.csv')).values.reshape(-1)\n",
    "ds_names = ['ds1', 'ds2', 'ds3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(X, y, n_samples):\n",
    "    return next(StratifiedShuffleSplit(n_splits=1, test_size=n_samples).split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_idx, ts_idx = random_sampling(ds, label, n_samples=0.25)\n",
    "\n",
    "ds1 = np.hstack([ds[:,:5], ds[:,10:15]])\n",
    "ds1_tr = ds1[tr_idx]\n",
    "ds1_ts = ds1[ts_idx]\n",
    "\n",
    "ds2 = np.hstack([ds[:,5:10], ds[:,15:20]])\n",
    "ds2_tr = ds2[tr_idx]\n",
    "ds2_ts = ds2[ts_idx]\n",
    "\n",
    "ds3 = ds[:,20:]\n",
    "ds3_tr = ds3[tr_idx]\n",
    "ds3_ts = ds3[ts_idx]\n",
    "\n",
    "y_t_ = label[tr_idx]\n",
    "y_t_test = label[ts_idx]\n",
    "\n",
    "ds_list_complete = [ds1, ds2, ds3]\n",
    "ds_list = [ds1_tr, ds2_tr, ds3_tr]\n",
    "ds_test = [ds1_ts, ds2_ts, ds3_ts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_0 = ['linear', 'polynomial', 'gaussian']\n",
    "kernel_type_0 = [{'linear':[0.5], 'polynomial':[2, 3, 7], 'gaussian':[0.1, 0.5, 0.7]},\n",
    "               {'linear':[0.2], 'polynomial':[4, 5, 8], 'gaussian':[0.7, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_1 = ['laplacian', 'polynomial', 'gaussian']\n",
    "kernel_type_1 = [{'laplacian':[0.1, 0.2, 0.3], 'polynomial':[2, 3], 'gaussian':[0.2, 0.3]},\n",
    "               {'laplacian':[0.5, 0.7], 'polynomial':[5, 8], 'gaussian':[0.5, 0.7]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_2 = ['sigmoid', 'polynomial', 'gaussian']\n",
    "kernel_type_2 = [{'sigmoid':[0.1, 0.2, 0.3], 'polynomial':[2, 3], 'gaussian':[0.2, 0.3]},\n",
    "               {'sigmoid':[0.5, 0.7], 'polynomial':[5, 8], 'gaussian':[0.5, 0.7]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_3 = ['laplacian', 'gaussian']\n",
    "kernel_type_3 = [{'laplacian':[0.2, 0.6], 'gaussian':[0.3, 0.6]},\n",
    "               {'laplacian':[0.4, 0.9], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_4 = ['linear', 'gaussian']\n",
    "kernel_type_4 = [{'linear':[1], 'gaussian':[0.3, 0.6]},\n",
    "               {'linear':[1], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_5 = ['polynomial', 'gaussian']\n",
    "kernel_type_5 = [{'polynomial':[2, 7], 'gaussian':[0.3, 0.6]},\n",
    "               {'polynomial':[3, 5], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_6 = ['sigmoid', 'gaussian']\n",
    "kernel_type_6 = [{'sigmoid':[0.2, 0.6], 'gaussian':[0.3, 0.6]},\n",
    "               {'sigmoid':[0.4, 0.9], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other shared parameters initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ca.centeredKernelAlignment\n",
    "lock_toy = Lock()\n",
    "valid_fold = 3\n",
    "threads = []\n",
    "pen_params = [0.5, 0.7, 0.9, 1.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def child(sampler, estimator, ds_list, ds_test ,y_t_, y_t_test, lock_toy, valid_fold, exclusion_list, verbose, approach):\n",
    "\n",
    "    #TOY\n",
    "    \n",
    "    # Linear, Polynomial, Gaussian\n",
    "    result1 = sampler.sample(kernel_type_0, estimator, ds_list, y_t_, valid_fold = valid_fold, verbose=verbose)\n",
    "    w_dict, w_list, lamb_list, sparsity = result1.votingOverCA(ds_names, kernel_names_0)\n",
    "    ut.testConfigurations(estimator, y_t_, y_t_test, w_list, ds_list, ds_test, kernel_names_0, lamb_list, sparsity, 'classification', lock_toy, fileToWrite = 'results_temp/Toy_test.txt', header = 'Toy Linear - Polynomial - Gaussian\\n' + approach + '\\n', normalize = sampler.normalize_kernels, verbose=verbose)\n",
    "    result1.performancesFeatures(fileToWrite = 'results_temp/Toy_train.txt', header='\\nToy Linear - Polynomial - Gaussian\\n' + approach + '\\n', lock = lock_toy)\n",
    "    \n",
    "    # Laplacian, Polynomial, Gaussian\n",
    "    result1 = sampler.sample(kernel_type_1, estimator, ds_list, y_t_, valid_fold = valid_fold, verbose=verbose)\n",
    "    w_dict, w_list, lamb_list, sparsity = result1.votingOverCA(ds_names, kernel_names_1)\n",
    "    ut.testConfigurations(estimator, y_t_, y_t_test, w_list, ds_list, ds_test, kernel_names_1, lamb_list, sparsity, 'classification', lock_toy, fileToWrite = 'results_temp/Toy_test.txt', header = 'Toy Laplacian - Polynomial - Gaussian \\n' + approach + '\\n', normalize = sampler.normalize_kernels, verbose=verbose)\n",
    "    result1.performancesFeatures(fileToWrite = 'results_temp/Toy_train.txt', header='\\nToy Laplacian - Polynomial - Gaussian\\n' + approach + '\\n', lock = lock_toy)\n",
    "    \n",
    "    # Sigmoid, Polynomial, Gaussian\n",
    "    result1 = sampler.sample(kernel_type_2, estimator, ds_list, y_t_, valid_fold = valid_fold, verbose=verbose)\n",
    "    w_dict, w_list, lamb_list, sparsity = result1.votingOverCA(ds_names, kernel_names_2)\n",
    "    ut.testConfigurations(estimator, y_t_, y_t_test, w_list, ds_list, ds_test, kernel_names_2, lamb_list, sparsity, 'classification', lock_toy, fileToWrite = 'results_temp/Toy_test.txt', header = 'Toy Sigmoid - Polynomial - Gaussian \\n' + approach + '\\n', normalize = sampler.normalize_kernels, verbose=verbose)\n",
    "    result1.performancesFeatures(fileToWrite = 'results_temp/Toy_train.txt', header='\\nToy Sigmoid - Polynomial - Gaussian\\n' + approach + '\\n', lock = lock_toy)\n",
    "    \n",
    "    #Laplacian - Gaussian\n",
    "    result1 = sampler.sample(kernel_type_3, estimator, ds_list, y_t_, valid_fold = valid_fold, verbose=verbose)\n",
    "    w_dict, w_list, lamb_list, sparsity = result1.votingOverCA(ds_names, kernel_names_3)\n",
    "    ut.testConfigurations(estimator, y_t_, y_t_test, w_list, ds_list, ds_test, kernel_names_3, lamb_list, sparsity, 'classification', lock_toy, fileToWrite = 'results_temp/Toy_test.txt', header = 'Toy Laplacian - Gaussian \\n' + approach + '\\n', normalize = sampler.normalize_kernels, verbose=verbose)\n",
    "    result1.performancesFeatures(fileToWrite = 'results_temp/Toy_train.txt', header='\\nToy Laplacian - Gaussian\\n' + approach + '\\n', lock = lock_toy)\n",
    "    \n",
    "    #Linear - Gaussian\n",
    "    result1 = sampler.sample(kernel_type_4, estimator, ds_list, y_t_, valid_fold = valid_fold, verbose=verbose)\n",
    "    w_dict, w_list, lamb_list, sparsity = result1.votingOverCA(ds_names, kernel_names_4)\n",
    "    ut.testConfigurations(estimator, y_t_, y_t_test, w_list, ds_list, ds_test, kernel_names_4, lamb_list, sparsity, 'classification', lock_toy, fileToWrite = 'results_temp/Toy_test.txt', header = 'Toy Linear - Gaussian \\n' + approach + '\\n', normalize = sampler.normalize_kernels, verbose=verbose)\n",
    "    result1.performancesFeatures(fileToWrite = 'results_temp/Toy_train.txt', header='\\nToy Linear - Gaussian\\n' + approach + '\\n', lock = lock_toy)\n",
    "    \n",
    "    #Polynomial - Gaussian\n",
    "    result1 = sampler.sample(kernel_type_5, estimator, ds_list, y_t_, valid_fold = valid_fold, verbose=verbose)\n",
    "    w_dict, w_list, lamb_list, sparsity = result1.votingOverCA(ds_names, kernel_names_5)\n",
    "    ut.testConfigurations(estimator, y_t_, y_t_test, w_list, ds_list, ds_test, kernel_names_5, lamb_list, sparsity, 'classification', lock_toy, fileToWrite = 'results_temp/Toy_test.txt', header = 'Toy Polynomial - Gaussian \\n' + approach + '\\n', normalize = sampler.normalize_kernels, verbose=verbose)\n",
    "    result1.performancesFeatures(fileToWrite = 'results_temp/Toy_train.txt', header='\\nToy Polynomial - Gaussian\\n' + approach + '\\n', lock = lock_toy)\n",
    "    \n",
    "    #Sigmoid - Gaussian\n",
    "    result1 = sampler.sample(kernel_type_6, estimator, ds_list, y_t_, valid_fold = valid_fold, verbose=verbose)\n",
    "    w_dict, w_list, lamb_list, sparsity = result1.votingOverCA(ds_names, kernel_names_6)\n",
    "    ut.testConfigurations(estimator, y_t_, y_t_test, w_list, ds_list, ds_test, kernel_names_6, lamb_list, sparsity, 'classification', lock_toy, fileToWrite = 'results_temp/Toy_test.txt', header = 'Toy Sigmoid - Gaussian \\n' + approach + '\\n', normalize = sampler.normalize_kernels, verbose=verbose)\n",
    "    result1.performancesFeatures(fileToWrite = 'results_temp/Toy_train.txt', header='\\nToy Sigmoid - Gaussian\\n' + approach + '\\n', lock = lock_toy)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Penalty, Centering, Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ms.mySampleWrapper(pen_params, n_splits=3, test_size=.25, sparsity = False, centering = True, normalizing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=child, args=([sampler, estimator, ds_list, ds_test, y_t_, y_t_test, lock_toy, valid_fold, None, False, 'L2 - Centering - Normalizing']))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Penalty, Centering, K-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ms.mySampleWrapper(pen_params, n_splits=3, test_size=0.25, sparsity = False, centering = True, normalize_kernels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=child, args=(sampler, estimator, ds_list, ds_test, y_t_, y_t_test, lock_toy, valid_fold, None, False, 'L2 - Centering - K Normalizing'))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Operations completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Penalty, Centering, Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ms.mySampleWrapper(pen_params, n_splits=3, test_size=.25, sparsity = True, centering = True, normalizing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=child, args=([sampler, estimator, ds_list, ds_test, y_t_, y_t_test, lock_toy, valid_fold, None, False, 'L1 - Centering - Normalizing']))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Penalty, Centering, K-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ms.mySampleWrapper(pen_params, n_splits=3, test_size=.25, sparsity = True, centering = True, normalize_kernels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=child, args=(sampler, estimator, ds_list, ds_test, y_t_, y_t_test, lock_toy, valid_fold, None, False, 'L1 - Centering - K Normalizing'))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Operations completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
