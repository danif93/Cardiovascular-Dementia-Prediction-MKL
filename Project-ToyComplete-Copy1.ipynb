{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilo/.conda/envs/bcb/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import Utils as ut\n",
    "import CortesAlignmentFile as ca\n",
    "import mySampler as ms\n",
    " \n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "\n",
    "from threading import Thread, Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(os.path.join('data', 'toyDataset.csv')).values\n",
    "label = pd.read_csv(os.path.join('data', 'toyLabel.csv')).values.reshape(-1)\n",
    "ds_names = ['ds1', 'ds2', 'ds3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(X, y, n_samples):\n",
    "    return next(StratifiedShuffleSplit(n_splits=1, test_size=n_samples).split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_idx, ts_idx = random_sampling(ds, label, n_samples=0.25)\n",
    "\n",
    "ds1 = np.hstack([ds[:,:5], ds[:,10:15]])\n",
    "ds1_tr = ds1[tr_idx]\n",
    "ds1_ts = ds1[ts_idx]\n",
    "\n",
    "ds2 = np.hstack([ds[:,5:10], ds[:,15:20]])\n",
    "ds2_tr = ds2[tr_idx]\n",
    "ds2_ts = ds2[ts_idx]\n",
    "\n",
    "ds3 = ds[:,20:]\n",
    "ds3_tr = ds3[tr_idx]\n",
    "ds3_ts = ds3[ts_idx]\n",
    "\n",
    "y_t_ = label[tr_idx]\n",
    "y_t_test = label[ts_idx]\n",
    "\n",
    "ds_list_complete = [ds1, ds2, ds3]\n",
    "ds_list = [ds1_tr, ds2_tr, ds3_tr]\n",
    "ds_test = [ds1_ts, ds2_ts, ds3_ts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_0 = ['laplacian', 'gaussian']\n",
    "kernel_type_0 = [{'laplacian':[0.2, 0.6], 'gaussian':[0.3, 0.7]},\n",
    "               {'laplacian':[0.4, 0.9], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_1 = ['linear', 'gaussian']\n",
    "kernel_type_1 = [{'linear':[1], 'gaussian':[0.4, 0.7]},\n",
    "               {'linear':[1], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_2 = ['polynomial', 'gaussian']\n",
    "kernel_type_2 = [{'polynomial':[2, 7], 'gaussian':[0.4, 0.7]},\n",
    "               {'polynomial':[3, 5], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names_3 = ['sigmoid', 'gaussian']\n",
    "kernel_type_3 = [{'sigmoid':[0.2, 0.6], 'gaussian':[0.3, 0.7]},\n",
    "               {'sigmoid':[0.4, 0.9], 'gaussian':[0.5, 1]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_toy = Lock()\n",
    "\n",
    "kernel_names = [kernel_names_0, kernel_names_1, kernel_names_2, kernel_names_3]\n",
    "kernel_types = [kernel_type_0, kernel_type_1, kernel_type_2, kernel_type_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other shared parameters initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ca.centeredKernelAlignment\n",
    "\n",
    "threads = []\n",
    "\n",
    "valid_fold = 3\n",
    "\n",
    "exclusion_list = None\n",
    "\n",
    "l1_params = [0.1, 0.3, 0.5, 0.7, 0.1]\n",
    "l2_params = [0.1, 0.3, 0.5, 0.7, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeKernels(sampler, estimator, penalty_type, parameter, ds_list, ds_test, y_, y_test, valid_fold, exclusion_list, verbose, approach):\n",
    "    \n",
    "    results = np.empty(len(kernel_names))\n",
    "    \n",
    "    for idx, (k_names, k_type) in enumerate(zip(kernel_names, kernel_types)):\n",
    "        \n",
    "        result = sampler.sample(k_type, estimator, ds_list, y_, valid_fold=valid_fold, verbose=verbose, exclusion_list=exclusion_list)\n",
    "        w_dict, w_list = result.votingOverCA(ds_names, k_names)\n",
    "        ut.testConfigurations(estimator, penalty_type, parameter, y_, y_test, w_list, ds_list, ds_test, k_names, 'classification', verbose=verbose)\n",
    "        outcome_dict = result.performancesFeatures(verbose=verbose)\n",
    "        results[idx] = outcome_dict['CA'][0]\n",
    "    \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectParam(params, penalty_type, train_set_list, train_label, estimator, approach, n_splits=3, centering=False, normalizing=False, normalize_kernels=False, exclusion_list=None, verbose=False):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=False)\n",
    "    \n",
    "    n_params = len(params)\n",
    "    n_kernels = len(kernel_names)\n",
    "    \n",
    "    results = np.zeros((n_params, n_kernels))\n",
    "    \n",
    "    for tr_idx, val_idx in skf.split(train_set_list[0], train_label):\n",
    "        tr_set_list = [X[tr_idx] for X in train_set_list]\n",
    "        val_set_list = [X[val_idx] for X in train_set_list]\n",
    "        tr_label = train_label[tr_idx]\n",
    "        val_label = train_label[val_idx]\n",
    "        \n",
    "        for idx, param in enumerate(params):\n",
    "            if penalty_type == 'l1':\n",
    "                sampler = ms.mySampler(n_splits=3, test_size=.25, sparsity=param, centering=centering, normalizing=normalizing, normalize_kernels=normalize_kernels)\n",
    "            elif penalty_type == 'l2':\n",
    "                sampler = ms.mySampler(n_splits=3, test_size=.25, lamb=param, centering=centering, normalizing=normalizing, normalize_kernels=normalize_kernels)\n",
    "            else:\n",
    "                raise ValueError('Penalty type not set properly')\n",
    "            \n",
    "            results[idx] += executeKernels(sampler, estimator, penalty_type, param, tr_set_list, val_set_list, tr_label, val_label, n_splits, exclusion_list, verbose, approach)\n",
    "    results /= skf.get_n_splits\n",
    "    avg_results = np.sum(results, axis=0)/n_kernels\n",
    "    print(approach+\"\\n\"+avg_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Penalty, Origin Data  Centering and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l2_params, 'l2', ds_list, y_t_, estimator, 'Centering - Normalizing', valid_fold, True, True, False, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Penalty, Origin Data  Centering and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l1_params, 'l1', ds_list, y_t_, estimator, 'Centering - Normalizing', valid_fold, True, True, False, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Penalty, Normalization, Kernel Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l2_params, 'l2', ds_list, y_t_, estimator, 'Normalizing - K Normalizing', valid_fold, False, True, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Penalty, Normalization, Kernel Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l1_params, 'l1', ds_list, y_t_, estimator, 'Normalizing - K Normalizing', valid_fold, False, True, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Penalty, Centering, Normalization, Kernel Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l2_params, 'l2', ds_list, y_t_, estimator, 'Centering - Normalizing - K Normalizing', valid_fold, True, True, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Penalty, Centering, Normalization, Kernel Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l1_params, 'l1', ds_list, y_t_, estimator, 'Centering - Normalizing - K Normalizing', valid_fold, True, True, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Penalty, Centering, K-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l2_params, 'l2', ds_list, y_t_, estimator, 'Centering - K Normalizing', valid_fold, True, False, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Penalty, Centering, K-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thread(target=selectParam, args=(l1_params, 'l1', ds_list, y_t_, estimator, 'Centering - K Normalizing', valid_fold, True, False, True, exclusion_list, False))\n",
    "t.start()\n",
    "threads.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilo/Desktop/BCB_Project/myLasso3.py:24: RuntimeWarning: invalid value encountered in true_divide\n",
      "  eta_new /= np.linalg.norm(eta_new)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-aeb54690ce94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Operations completed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bcb/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/bcb/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Operations completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
