{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import Utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "# make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, \n",
    "#                     n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, \n",
    "#                     hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "ds, label = datasets.make_classification(n_samples=300, n_features=30, n_informative=10, n_redundant=0, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(label==0)\n",
    "label[np.where(label==0)]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(X, y, n_samples):\n",
    "    \"\"\"Extract n_samples from X and y.\"\"\"\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    \n",
    "    return next(StratifiedShuffleSplit(n_splits=1, test_size=n_samples).split(X, y))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_idx, ts_idx = random_sampling(ds, label, n_samples=0.25)\n",
    "\n",
    "\n",
    "ds1 = np.hstack([ds[:,:5], ds[:,10:15]])\n",
    "ds1_tr = ds1[tr_idx]\n",
    "ds1_ts = ds1[ts_idx]\n",
    "\n",
    "ds2 = np.hstack([ds[:,5:10], ds[:,15:20]])\n",
    "ds2_tr = ds2[tr_idx]\n",
    "ds2_ts = ds2[ts_idx]\n",
    "\n",
    "ds3 = ds[:,20:]\n",
    "ds3_tr = ds3[tr_idx]\n",
    "ds3_ts = ds3[ts_idx]\n",
    "\n",
    "l_tr = label[tr_idx]\n",
    "l_ts = label[ts_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_types = ['linear', 'polynomial', 'gaussian']\n",
    "k_dataset_wrapper = []\n",
    "k_train_list = []\n",
    "k_test_list = []\n",
    "\n",
    "for train, test in zip([ds1_tr, ds2_tr, ds3_tr], [ds1_ts, ds2_ts, ds3_ts]):\n",
    "    for k_type in kernel_types:\n",
    "        if k_type=='polynomial': \n",
    "            current = ut.kernel(train, K_type=k_type, param=10)\n",
    "        else:\n",
    "            current = ut.kernel(train, K_type=k_type, param=2)\n",
    "            \n",
    "        k_dataset_wrapper.append({'kernel':current, 'train_ds':train, 'test_ds':test})\n",
    "        k_train_list.append(current.kernelMatrix(train))\n",
    "        k_test_list.append(current.kernelMatrix(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idealK_overTr = np.dot(l_tr.reshape(-1,1), l_tr.reshape(-1,1).T)\n",
    "new_kernels_config = ut.parameterOptimization(k_dataset_wrapper, l_tr, n_epoch=100, tol=0.0001, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ut.centeredKernelAlignment(k_train_list, l_tr)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = {'linear': [0], 'polynomial': [2,3,4], 'gaussian':[0.3, 0.5, 0.7]}\n",
    "eta, ca, params = ut.centeredKernelAlignmentCV(kernel_type, [ds1_tr, ds2_tr, ds3_tr], l_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros(len(ts_idx))\n",
    "for k_test, w in zip(k_test_list, weights):\n",
    "    weighted_labeled_kernel = np.multiply(k_test, l_tr*w)  \n",
    "    pred += np.sum(weighted_labeled_kernel, axis=1)\n",
    "pred = np.sign(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(l_ts, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "print(a.ravel().reshape(-1,1).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
