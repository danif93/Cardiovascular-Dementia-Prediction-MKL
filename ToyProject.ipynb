{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Utils as ut\n",
    "import KernelFile as kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "# make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, \n",
    "#                     n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, \n",
    "#                     hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "ds, label = datasets.make_classification(n_samples=300, n_features=30, n_informative=10, n_redundant=0, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(label==0)\n",
    "label[np.where(label==0)]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(X, y, n_samples):\n",
    "    \"\"\"Extract n_samples from X and y.\"\"\"\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    \n",
    "    return next(StratifiedShuffleSplit(n_splits=1, test_size=n_samples).split(X, y))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_idx, ts_idx = random_sampling(ds, label, n_samples=0.25)\n",
    "\n",
    "ds1 = np.hstack([ds[:,:5], ds[:,10:15]])\n",
    "ds1_tr = ds1[tr_idx]\n",
    "ds1_ts = ds1[ts_idx]\n",
    "\n",
    "ds2 = np.hstack([ds[:,5:10], ds[:,15:20]])\n",
    "ds2_tr = ds2[tr_idx]\n",
    "ds2_ts = ds2[ts_idx]\n",
    "\n",
    "ds3 = ds[:,20:]\n",
    "ds3_tr = ds3[tr_idx]\n",
    "ds3_ts = ds3[ts_idx]\n",
    "\n",
    "l_tr = label[tr_idx]\n",
    "l_ts = label[ts_idx]\n",
    "\n",
    "tr_list = [ds1_tr, ds2_tr, ds3_tr]\n",
    "ts_list = [ds1_ts, ds2_ts, ds3_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRIDSEARCH CV\n",
    "import myGridSearch as mgs\n",
    "\n",
    "kernel_type = {'linear':[0], 'polynomial':[2, 8, 12], 'gaussian':[0.1, 0.5, 0.7]}\n",
    "estimator = ut.centeredKernelAlignment\n",
    "gs = mgs.myGridSearchCV(estimator, kernel_type, fold = 3).fit(tr_list, l_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no. 0\n",
      "\t\tPerfomances computed for 50\n",
      "\t\tPerfomances computed for 100\n",
      "\t\tPerfomances computed for 150\n",
      "\t\tPerfomances computed for 200\n",
      "\t\tPerfomances computed for 250\n",
      "\t\tPerfomances computed for 300\n",
      "\t\tPerfomances computed for 350\n",
      "\t\tPerfomances computed for 400\n",
      "\t\tPerfomances computed for 450\n",
      "\t\tPerfomances computed for 500\n",
      "\t\tPerfomances computed for 550\n",
      "\t\tPerfomances computed for 600\n",
      "\t\tPerfomances computed for 650\n",
      "\t\tPerfomances computed for 700\n",
      "Fold no. 1\n",
      "\t\tPerfomances computed for 50\n",
      "\t\tPerfomances computed for 100\n",
      "\t\tPerfomances computed for 150\n",
      "\t\tPerfomances computed for 200\n",
      "\t\tPerfomances computed for 250\n",
      "\t\tPerfomances computed for 300\n",
      "\t\tPerfomances computed for 350\n",
      "\t\tPerfomances computed for 400\n",
      "\t\tPerfomances computed for 450\n",
      "\t\tPerfomances computed for 500\n",
      "\t\tPerfomances computed for 550\n",
      "\t\tPerfomances computed for 600\n",
      "\t\tPerfomances computed for 650\n",
      "\t\tPerfomances computed for 700\n",
      "Fold no. 2\n",
      "\t\tPerfomances computed for 50\n",
      "\t\tPerfomances computed for 100\n",
      "\t\tPerfomances computed for 150\n",
      "\t\tPerfomances computed for 200\n",
      "\t\tPerfomances computed for 250\n",
      "\t\tPerfomances computed for 300\n",
      "\t\tPerfomances computed for 350\n",
      "\t\tPerfomances computed for 400\n",
      "\t\tPerfomances computed for 450\n",
      "\t\tPerfomances computed for 500\n",
      "\t\tPerfomances computed for 550\n",
      "\t\tPerfomances computed for 600\n",
      "\t\tPerfomances computed for 650\n",
      "\t\tPerfomances computed for 700\n",
      "Validation complete, config selected:[[0, 2, 0.7], [0, 12, 0.7], [0, 2, 0.7]]\n"
     ]
    }
   ],
   "source": [
    "weights = gs.transform(tr_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08549238732906818,\n",
       " [[0, 2, 0.7], [0, 12, 0.7], [0, 2, 0.7]],\n",
       " array([ 4.75795012e-04, -1.79672482e-03, -4.29313087e-01,  8.28923904e-04,\n",
       "        -2.99704695e-14,  8.56960466e-01, -1.44839027e-03,  6.71889960e-03,\n",
       "        -2.85057273e-01]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleMKL APPROACH\n",
    "\n",
    "# kernel_type = {'linear': [0], 'polynomial': [2,3,4], 'gaussian':[0.3, 0.5, 0.7]}\n",
    "kernel_type = {'linear': 0, 'polynomial': 4, 'gaussian': 0.5}\n",
    "\n",
    "smkl = ut.MKL_simpleSrola(kernel_type, 10, 0.01)\n",
    "smkl.fit(tr_list, l_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = smkl.learnEta(tr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cortes Alignment APPROACH\n",
    "\n",
    "kernel_types = ['linear', 'polynomial', 'gaussian']\n",
    "k_dataset_wrapper = []\n",
    "k_train_list = []\n",
    "k_test_list = []\n",
    "\n",
    "for train, test in zip(tr_list, ts_list):\n",
    "    for k_type in kernel_types:\n",
    "        if k_type=='polynomial': \n",
    "            current = kf.kernel(train, K_type=k_type, param=10)\n",
    "        else:\n",
    "            current = kf.kernel(train, K_type=k_type, param=2)\n",
    "            \n",
    "        k_dataset_wrapper.append({'kernel':current, 'train_ds':train, 'test_ds':test})\n",
    "        k_train_list.append(current.kernelMatrix(train))\n",
    "        k_test_list.append(current.kernelMatrix(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idealK_overTr = np.dot(l_tr.reshape(-1,1), l_tr.reshape(-1,1).T)\n",
    "new_kernels_config = ut.parameterOptimization(k_dataset_wrapper, l_tr, n_epoch=100, tol=0.0001, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ut.centeredKernelAlignment(k_train_list, l_tr)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros(len(ts_idx))\n",
    "for k_test, w in zip(k_test_list, weights):\n",
    "    weighted_labeled_kernel = np.multiply(k_test, l_tr*w)  \n",
    "    pred += np.sum(weighted_labeled_kernel, axis=1)\n",
    "pred = np.sign(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(l_ts, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "print(a.ravel().reshape(-1,1).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
